{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263f78ee",
   "metadata": {},
   "source": [
    "### Document specifications\n",
    "Author: Dominik Wulf <br>\n",
    "Matriculation Number: 364 100 <br>\n",
    "Creation Date: 06. September 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e35ee",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017093e",
   "metadata": {},
   "source": [
    "The data is structured as follows. The folders are separated into three different sections: Scraper, LDA, Bubble Tests and Latex. In order to review the code and use the right dataset, this file explains the usage of the different scripts. The numbers before the datasets or the filenames describe the dates the scrape or the data was collected as YYYYMMDD. For readability reasons it is advised to use the jupyter notebooks to review the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4f2c3",
   "metadata": {},
   "source": [
    "## Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69dc6d7",
   "metadata": {},
   "source": [
    "The Scraper contains the sections:<br>\n",
    "* Data\n",
    "* Output\n",
    "* Scraper Jupyter\n",
    "* Scraper Python <br>\n",
    "\n",
    "The Data contains the input data for the scraper. The file is named **'220704_project_website_links_nos'** and contains all individual links from [dappradar.com](https://dappradar.com/) from NFT projects. The list doesn't contain any links of the website [opensea.io](https://opensea.io/) which were also referenced for some projects on the website dappradar.com. The Scraper Jupyter, respectively Python contains two python scripts. \n",
    "<br> The first one is called **220705_scraper** which is the main script for the scraper. The links from the above named file are iteratively visited as described in chapter and the HTML content is collected as described in chapter 3.2.1. The output dataset from the script is called **'220705_html_content'**\n",
    "<br> The second script is called **Scrape Postprocessing** and uses the output dataset from the first script. The script removes duplicates and NaN values from the data and removes sublinks from the link list. The output dataset called **'220705_html_content_normalized'** is the final dataset used in the LDA model.\n",
    "<br> As a prerequesite to run the scrape, the chromedriver https://chromedriver.chromium.org/downloads has to be installed together with the chrome browser.\n",
    "<br> In order for the scraper to work, the following files need to be downloaded and the respective links need to be inserted to import the data at the beginning of the script: <br>\n",
    "\n",
    "* **'220704_project_website_links_nos.csv'**,\n",
    "* **'220705_html_content.csv'**\n",
    "* **'220705_html_content_normalized.csv'**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e29208",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40f70cb",
   "metadata": {},
   "source": [
    "The LDA folder contains four parts:<br>\n",
    "* LDA Models Jupyter\n",
    "* LDA Models Python\n",
    "* Data\n",
    "* HTML output <br>\n",
    "\n",
    "The Data contains one file called **'220705_html_content_normalized'**. This file is the result of the scraper and has been prepared as described in chapter 3.2.1. Within the LDA files, only the websites with more than 10,000 words are removed. The ipynb files are the jupyter notebooks used to create the LDA models and produce the HTML output. Respectively the python files present a copy of the  The data The HTML output contains two files depicting the pyLDAvis inter topic distance map described in chapter 3 in the thesis. \n",
    "\n",
    "In order for the script to work please download the above named file and insert the filepath where indicated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f31e4",
   "metadata": {},
   "source": [
    "## Bubble Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cb2f90",
   "metadata": {},
   "source": [
    "The Bubble Test folder contains four parts:<br>\n",
    "* Data\n",
    "* Scripts\n",
    "* Figs\n",
    "* Bubble Tests<br>\n",
    "\n",
    "The Data folder contains all the time series for the NFT projects and their aggregated series retrieved from [nonfungible.com](https://nonfungible.com/market-tracker). **Bubble Tests** is the R project created for conducting the tests. The Scripts folder contains the aggregated tests, the test for the individual sections and the cryptocurrencies. The .md files can be viewed in github. The Figs folder contains the figures of the BSADF test on the time series.\n",
    "<br> As a prerequesite to run the r script the package [exuber](https://github.com/kvasilopoulos/exuber) among other common packages needs to be installed and additionally [exuberdata](https://github.com/kvasilopoulos/exuberdata) dataset needs to be retrieved. This is due as some datasets contain more than 600 observations and the exuberdata dataset contains critical values and critical value sequences for the GSADF and BSADF test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892924fb",
   "metadata": {},
   "source": [
    "## Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df17c5",
   "metadata": {},
   "source": [
    "The Latex folder contains the raw form of the Latex file, the bibliography in .bibtex format and a completed PDF version of the thesis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
