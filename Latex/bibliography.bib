@article{Chalmers2022,
   author = {Dominic Chalmers and Christian Fisch and Russell Matthews and William Quinn and Jan Recker},
   doi = {10.1016/J.JBVI.2022.E00309},
   issn = {2352-6734},
   journal = {Journal of Business Venturing Insights},
   month = {6},
   pages = {e00309},
   publisher = {Elsevier},
   title = {Beyond the bubble: Will NFTs and digital proof of ownership empower creative industry entrepreneurs?},
   volume = {17},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S2352673422000075},
   year = {2022},
}
@article{Pinto2022,
   abstract = {Non-fungible tokens (NFTs) can be used to represent ownership of digital art or any other unique digital item where ownership is recorded in smart contracts on a blockchain. NFTs have recently received enormous attention from both cryptocurrency investors and the media. We examine why NFTs have gotten so much attention. Using vector autoregressive models, we show that Bitcoin returns significantly predict next week&rsquo;s NFT growth in popularity, measured by Google search queries. Moreover, wavelet coherence analysis suggests that Bitcoin and Ether returns are significant drivers of next week&rsquo;s attention to NFTs. These results indicate that the remarkable increases in prices of major cryptocurrencies can explain the hype around NFTs.},
   author = {Christian Pinto-Gutiérrez and Sandra Gaitán and Diego Jaramillo and Simón Velasquez},
   doi = {10.3390/MATH10030335},
   issn = {2227-7390},
   issue = {3},
   journal = {Mathematics 2022, Vol. 10, Page 335},
   keywords = {NFT,cryptocurrency,fungible tokens,investor attention,non},
   month = {1},
   pages = {335},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {The NFT Hype: What Draws Attention to Non-Fungible Tokens?},
   volume = {10},
   url = {https://www.mdpi.com/2227-7390/10/3/335/htm https://www.mdpi.com/2227-7390/10/3/335},
   year = {2022},
}
@article{Vasan2022,
   abstract = {The evolution of the art ecosystem is driven by largely invisible networks, defined by undocumented interactions between artists, institutions, collectors and curators. The emergence of cryptoart, and the NFT-based digital marketplace around it, offers unprecedented opportunities to examine the mechanisms that shape the evolution of networks that define artistic practice. Here we mapped the Foundation platform, identifying over 48,000 artworks through the associated NFTs listed by over 15,000 artists, allowing us to characterize the patterns that govern the networks that shape artistic success. We find that NFT adoption by both artists and collectors has undergone major changes, starting with a rapid growth that peaked in March 2021 and the emergence of a new equilibrium in June. Despite significant changes in activity, the average price of the sold art remained largely unchanged, with the price of an artist’s work fluctuating in a range that determines his or her reputation. The artist invitation network offers evidence of rich and poor artist clusters, driven by homophily, indicating that the newly invited artists develop similar engagement and sales patterns as the artist who invited them. We find that successful artists receive disproportional, repeated investment from a small group of collectors, underscoring the importance of artist–collector ties in the digital marketplace. These reproducible patterns allow us to characterize the features, mechanisms, and the networks enabling the success of individual artists, a quantification necessary to better understand the emerging NFT ecosystem.},
   author = {Kishore Vasan and Milán Janosov and Albert László Barabási},
   doi = {10.1038/s41598-022-05146-6},
   isbn = {0123456789},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports 2022 12:1},
   keywords = {Computational science,Computer science,Mathematics and computing},
   month = {2},
   pages = {1-11},
   pmid = {35177628},
   publisher = {Nature Publishing Group},
   title = {Quantifying NFT-driven networks in crypto art},
   volume = {12},
   url = {https://www.nature.com/articles/s41598-022-05146-6},
   year = {2022},
}
@article{Geuder2019,
   abstract = {We study bubble behavior in Bitcoin prices during the years 2016 to 2018 based on two distinct testing methodologies. The Phillips et al. (2015) PSY methodology is used to identify multiple bubble periods. The log-periodic power law (LPPL) approach by Filimonov and Sornette (2013) identifies bubble growth and potential critical bubble termination times. Our results underline that bubble behavior is clearly a common and reoccurring characteristic of Bitcoin prices. A critical time point is identified to be December 6, 2017, after which neither approach provides evidence of ongoing bubble behavior.},
   author = {Julian Geuder and Harald Kinateder and Niklas F. Wagner},
   doi = {10.1016/J.FRL.2018.11.011},
   issn = {1544-6123},
   journal = {Finance Research Letters},
   keywords = {Bitcoin,Bubble periods,Cryptocurrencies,Explosive price behavior,Financial bubbles,Log-periodic power law},
   month = {12},
   pages = {179-184},
   publisher = {Elsevier},
   title = {Cryptocurrencies as financial bubbles: The case of Bitcoin},
   volume = {31},
   year = {2019},
}
@article{Chaim2019,
   abstract = {The narrative of a Bitcoin is a bubble is very common. We employ statistical techniques to empirically evaluate such claim. A branch of literature links the existence of a bubble in some financial asset's price to strict local martingales — a finitely lived asset has a bubble if, and only if, it is a strict local martingale under the equivalent risk-neutral measure. A diffusion process is a strict local martingale if its volatility increases faster than linearly as its level grows. We apply a nonparametric method to estimate the volatility function of Bitcoin daily and high frequency prices, as well as of more traditional financial assets. We then estimate the stochastic volatility model of Andersen and Piterbarg (2007), whose parameter space has a specific subset under which the asset's price is a strict local martingale. Results suggest the existence of a bubble in Bitcoin prices from early 2013 to mid 2014, but, interestingly, not in late 2017.},
   author = {Pedro Chaim and Márcio P. Laurini},
   doi = {10.1016/J.PHYSA.2018.11.031},
   issn = {0378-4371},
   journal = {Physica A: Statistical Mechanics and its Applications},
   keywords = {Bitcoin,Cryptocurrencies,Financial bubbles,Strict local martingales},
   month = {3},
   pages = {222-232},
   publisher = {North-Holland},
   title = {Is Bitcoin a bubble?},
   volume = {517},
   year = {2019},
}
@web_page{Padtberg2021,
   author = {Carola Padtberg},
   journal = {Der Spiegel},
   title = {»Art Power 100«-Ranking: Die Blockchain hat die Kunst im Griff},
   url = {https://www.spiegel.de/kultur/art-power-100-ranking-die-blockchain-hat-die-kunst-im-griff-a-989bd8b7-4d42-4250-bdcd-fcba7f25cd87},
   year = {2021},
}
@article{Jiang2021,
   abstract = {CryptoKitties was the first widely recognized blockchain game. Players could own, breed, and trade kitties, which are the only prop in the game. The game gained explosive growth upon its release but quickly collapsed in a short time. This study analyzes its entire player activity history for the first time in literature and tries to find the reasons for the rise and fall of this first blockchain game mania. First, we extracted the five million transaction records among 100 thousand addresses involved in CryptoKitties in the past three years. Based on the numbers of addresses involved in the game each day, we divide the game progress into four stages: the primer, the rise, the fall, and the serenity. We construct a temporal kitty ownership transfer network and analyze the varying network parameters in the four stages. We find that a large number of players poured in during the 10th and 18th days since the game release and quickly exited in the following month. Since then, a few big players have gradually dominated the game, concentrating the game resources. Through further analysis, we find that the main reason for the rapid increase in the game popularity was the increase of public attention by media outlets, while the reasons for the rapid decline in the game popularity include the oversupply of kitties, the decreasing of player income, a widening gap between the rich and poor players, and the limitations of blockchain systems. Based on these observations, we advise on the further blockchain game design: (1) to finely control the production of props and avoid an oversupply, (2) to balance the gaming cost and revenue and protect the enjoyment of players, (3) to narrow down the gap between rich and poor and create an equal gaming community, (4) to consider the limitations of blockchain systems in their game designs.},
   author = {Xin Jian Jiang and Xiao Fan Liu},
   doi = {10.3389/FPHY.2021.631665/BIBTEX},
   issn = {2296424X},
   journal = {Frontiers in Physics},
   keywords = {blockchain game,cryptokitties,ethereum,game design,transaction network},
   month = {3},
   pages = {57},
   publisher = {Frontiers Media S.A.},
   title = {CryptoKitties Transaction Network Analysis: The Rise and Fall of the First Blockchain Game Mania},
   volume = {9},
   year = {2021},
}
@newspaper_article{Economist2021,
   author = {Economist},
   journal = {The Economist},
   title = {What is an NFT? | The Economist},
   url = {https://www.economist.com/the-economist-explains/2021/10/12/what-is-an-nft},
   year = {2021},
}
@article{Phillips2018,
   abstract = {Expansion and collapse are two key features of a financial asset bubble. Bubble expansion may be modeled using a mildly explosive process. Bubble implosion may take several different forms depending on the nature of the collapse and therefore requires some flexibility in modeling. This paper first strengthens the theoretical foundation of the real time bubble monitoring strategy proposed in Phillips, Shi and Yu (2015a,b, PSY) by developing analytics and studying the performance characteristics of the testing algorithm under alternative forms of bubble implosion which capture various return paths to market normalcy. Second, we propose a new reverse sample use of the PSY procedure for detecting crises and estimating the date of market recovery. Consistency of the dating estimators is established and the limit theory addresses new complications arising from the alternative forms of bubble implosion and the endogeneity effects present in the reverse regression. A real-time version of the strategy is provided that is suited for practical implementation. Simulations explore the finite sample performance of the strategy for dating market recovery. The use of the PSY strategy for bubble monitoring and the new procedure for crisis detection are illustrated with an application to the Nasdaq stock market.},
   author = {Peter C.B. Phillips and Shu Ping Shi},
   doi = {10.1017/S0266466617000202},
   issn = {0266-4666},
   issue = {4},
   journal = {Econometric Theory},
   month = {8},
   pages = {705-753},
   publisher = {Cambridge University Press},
   title = {FINANCIAL BUBBLE IMPLOSION AND REVERSE REGRESSION},
   volume = {34},
   url = {https://www.cambridge.org/core/journals/econometric-theory/article/financial-bubble-implosion-and-reverse-regression/E43AC1EFA8A36467BAF4C602950B6074},
   year = {2018},
}
@article{Obayashi2017,
   abstract = {We combine both a mathematical analysis of financial bubbles and a statistical procedure for determining when a given stock is in a bubble, with an analysis of a large data set, in order to compute the empirical distribution of the lifetime of financial bubbles. We find that it follows a generalized gamma distribution, and we provide estimates for its parameters. We also perform goodness of fit tests, and we provide a derivation, within the context of bubbles, that explains why the generalized gamma distribution might be the natural one to expect for the lifetimes of financial bubbles.},
   author = {Yoshiki Obayashi and Philip Protter and Shihao Yang},
   doi = {10.1007/S11579-016-0170-Z/FIGURES/3},
   issn = {18629660},
   issue = {1},
   journal = {Mathematics and Financial Economics},
   keywords = {Bubble lifetimes,Financial bubbles,Generalized gamma distributions,Strict local martingales},
   month = {1},
   pages = {45-62},
   publisher = {Springer Verlag},
   title = {The lifetime of a financial bubble},
   volume = {11},
   url = {https://link.springer.com/article/10.1007/s11579-016-0170-z},
   year = {2017},
}
@article{Sornette2013,
   abstract = {The Johansen-Ledoit-Sornette (JLS) model of rational expectation bubbles with finite-time singular crash hazard rates has been developed to describe the dynamics of financial bubbles and crashes. It has been applied successfully to a large variety of financial bubbles in many different markets. Having been developed over a decade ago, the JLS model has been studied, analyzed, used and criticized by several researchers. Much of this discussion is helpful for advancing the research. However, several serious misconceptions seem to be present within this literature both on theoretical and empirical aspects. Several of these problems stem from the fast evolution of the literature on the JLS model and related works. In the hope of removing possible misunderstanding and of catalyzing useful future developments, we summarize these common questions and criticisms concerning the JLS model and synthesize the current state of the art and existing best practice. © 2013 Elsevier B.V. All rights reserved.},
   author = {Didier Sornette and Ryan Woodard and Wanfeng Yan and Wei Xing Zhou},
   doi = {10.1016/J.PHYSA.2013.05.011},
   issn = {0378-4371},
   issue = {19},
   journal = {Physica A: Statistical Mechanics and its Applications},
   keywords = {Crashes,Financial bubbles,JLS model,Log-periodic power law,Probabilistic forecast},
   month = {10},
   pages = {4417-4428},
   publisher = {North-Holland},
   title = {Clarifications to questions and criticisms on the Johansen–Ledoit–Sornette financial bubble model},
   volume = {392},
   year = {2013},
}
@article{Siegel2003,
   abstract = {This paper reviews and analyses the current definitions of bubbles in asset prices. It makes the case that one cannot identify a bubble immediately, but one has to wait a sufficient amount of time to determine whether the previous prices can be justified by subsequent cash flows. The paper proposes an operational definition of a bubble as any time the realised asset return over given future period is more than two standard deviations from its expected return. Using this framework, the paper shows how the great crash of 1929 and 1987—both periods generally characterised as bubbles—prove not to be bubbles but the low point in stock prices in 1932 is a ‘negative bubble.’ The paper then extends this analysis to the internet stocks and concludes that it is virtually certain that it is a bubble. © 2003 Blackwell Publishing Ltd.},
   author = {Jeremy J. Siegel},
   doi = {10.1111/1468-036X.00206},
   issn = {1468-036X},
   issue = {1},
   journal = {European Financial Management},
   keywords = {asset prices,asset returns,bubbles,internet bubble,irrational exuberance},
   month = {3},
   pages = {11-24},
   publisher = {John Wiley & Sons, Ltd},
   title = {What Is an Asset Price Bubble? An Operational Definition},
   volume = {9},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/1468-036X.00206},
   year = {2003},
}
@article{Phillips2011a,
   abstract = {A new recursive regression methodology is introduced to analyze the bubble characteristics of various financial time series during the subprime crisis. The methods modify a technique proposed in Phillips, Wu, and Yu (2011) and provide a technology for identifying bubble behavior with consistent dating of their origination and collapse. The tests serve as an early warning diagnostic of bubble activity and a new procedure is introduced for testing bubble migration across markets. Three relevant financial series are investigated, including a financial asset price (a house price index), a commodity price (the crude oil price), and one bond price (the spread between Baa and Aaa). Statistically significant bubble characteristics are found in all of these series. The empirical estimates of the origination and collapse dates suggest a migration mechanism among the financial variables. A bubble emerged in the real estate market in February 2002. After the subprime crisis erupted in 2007, the phenomenon migrated selectively into the commodity market and the bond market, creating bubbles which subsequently burst at the end of 2008, just as the effects on the real economy and economic growth became manifest. Our empirical estimates of the origination and collapse dates and tests of migration across markets match well with the general dateline of the crisis put forward in the recent study by Caballero, Farhi, and Gourinchas (2008a). Copyright ? 2011 Peter C. B. Phillips and Jun Yu.},
   author = {Peter C. B. Phillips and Jun Yu},
   doi = {10.3982/QE82},
   issn = {1759-7331},
   issue = {3},
   journal = {Quantitative Economics},
   keywords = {C15,Financial bubbles,G01,G12,crashes,date stamping,explosive behavior,migration,mildly explosive process,subprime crisis,timeline},
   month = {11},
   pages = {455-491},
   publisher = {John Wiley & Sons, Ltd},
   title = {Dating the timeline of financial bubbles during the subprime crisis},
   volume = {2},
   url = {https://onlinelibrary.wiley.com/doi/full/10.3982/QE82},
   year = {2011},
}
@article{Breaban2015,
   abstract = {We report results from an asset market experiment, in which we investigate the relationship between traders' risk aversion, loss aversion, and cognitive ability and their trading behavior and market outcomes. Greater average risk aversion on the part of traders in the market predicts lower market prices. The greater the level of loss aversion of the trader cohort, the lower the quantity traded. The greater the average cognitive reflection test score, the smaller the differences between market prices and fundamental values. Different treatments enable us to study how the time path of the fundamental value trajectory affects the level of adherence to fundamentals. We compare the level of mispricing between decreasing and increasing fundamental value trajectories. We find evidence for closer adherence to fundamental values when the trajectory follows a decreasing, than when it has an increasing, trend.},
   author = {Adriana Breaban and Charles N. Noussair},
   doi = {10.1016/J.JBEF.2015.07.005},
   issn = {2214-6350},
   journal = {Journal of Behavioral and Experimental Finance},
   keywords = {Bubble,CRT,Crash,Fundamental value},
   month = {12},
   pages = {1-17},
   publisher = {Elsevier},
   title = {Trader characteristics and fundamental value trajectories in an asset market experiment},
   volume = {8},
   year = {2015},
}
@book{Shiller2015,
   author = {Robert J. Shiller},
   doi = {10.1515/9781400865536},
   isbn = {9781400865536},
   month = {1},
   publisher = {Princeton University Press},
   title = {Irrational Exuberance},
   url = {https://www.degruyter.com/document/doi/10.1515/9781400865536/html},
   year = {2015},
}
@article{Moore2017,
   author = {Alyssa Moore and Joanne Artz and Craig R Ehlen},
   issn = {1942-6089},
   journal = {International Journal of the Academic Business World},
   pages = {47-52},
   title = {TULIP MANIA},
   url = {https://eds.p.ebscohost.com/eds/detail/detail?vid=0&sid=47221fad-ca4b-4612-9eda-1ec47cf58bb4%40redis&bdata=Jmxhbmc9ZGUmc2l0ZT1lZHMtbGl2ZQ%3d%3d#AN=125439972&db=bsx},
   year = {2017},
}
@article{Goodnight2010,
   abstract = {Post-conventional economic theories are assembled to inquire into the contingent, mimetic, symbolic, and material spirals unfolding the dot-com bubble, 1992–2002. The new technologies bubble is rec...},
   author = {G. Thomas Goodnight and Sandy Green},
   doi = {10.1080/00335631003796669},
   issn = {00335630},
   issue = {2},
   journal = {Quarterly Journal of Speech},
   keywords = {Attention Economy,Bubbles,Economic Criticism,Mimesis,Rhetoric of Economics},
   month = {5},
   pages = {115-140},
   publisher = { Taylor & Francis Group },
   title = {Rhetoric, Risk, and Markets: The Dot-Com Bubble},
   volume = {96},
   url = {https://www.tandfonline.com/doi/abs/10.1080/00335631003796669},
   year = {2010},
}
@article{DeLong2006,
   author = {J. Bradford DeLong and Konstantin Magin},
   city = {Cambridge, MA},
   doi = {10.3386/W12011},
   institution = {National Bureau of Economic Research},
   keywords = {J. Bradford DeLong,Konstantin Magin},
   month = {2},
   title = {A Short Note on the Size of the Dot-Com Bubble},
   url = {https://www.nber.org/papers/w12011},
   year = {2006},
}
@article{Morris2012,
   abstract = {During the dot-com bubble of the 1990s, equity market valuation was a popular topic for investors, financial analysts and academics. Some questioned whether traditional accounting and financial information had lost its value relevance, as stocks traded at multiples of earnings well in excess of historic levels, leading Alan Greenspan to caution against " irrational exuberance." This study examines the relation between market valuation and traditional accounting/financial information before, during and after the bubble. We confirm previous research that documents a decline in the relation between market value and traditional accounting information leading up to the bubble period. However, we also document that after the collapse of the bubble in 2000 this trend reverses. We also examine two related metrics that may provide a rational explanation for this phenomenon, including the quality of earnings, and the aggressiveness of financial analysts' forecasts, finding some support that earnings quality may contribute to the changes in value relevance, but not the aggressiveness of analyst forecasts. © 2012 The Board of Trustees of the University of Illinois.},
   author = {John J. Morris and Pervaiz Alam},
   doi = {10.1016/J.QREF.2012.04.001},
   issn = {1062-9769},
   issue = {2},
   journal = {The Quarterly Review of Economics and Finance},
   keywords = {Analyst forecast,Capital markets,Earnings quality,Equity valuation,New economy,Value relevance},
   month = {5},
   pages = {243-255},
   publisher = {North-Holland},
   title = {Value relevance and the dot-com bubble of the 1990s},
   volume = {52},
   year = {2012},
}
@web_page{Hayes2019,
   author = {Adam Hayes},
   journal = {Investopedia},
   title = {Dotcom Bubble Definition},
   url = {https://www.investopedia.com/terms/d/dotcom-bubble.asp},
   year = {2019},
}
@article{Penman2003,
   abstract = {During the recent stock market bubble, the traditional financial reporting model was assailed as a backward-looking system, out of date in the Information Age. With the bursting of the bubble, the quality of financial reporting is again under scrutiny, but now for not adhering to traditional principles of sound earnings measurement and asset and liability recognition. This paper is a retrospective on the quality of financial reporting during the 1990s. Did reporting under U.S. GAAP perform well during the bubble, or was its quality suspect? My premise is that financial reporting should serve as an anchor during bubbles, to check speculative beliefs. With a focus on the shareholder as customer, the paper asks whether shareholders were well served or whether financial reporting helped to pyramid earnings and stock prices. The scorecard is mixed. A number of quality features of accounting are identified. Inevitable imperfections due to measurement difficulties are recognized, as a quality warning to analysts and investors. A number of failures of GAAP and financial disclosures are identified that, if not recognized, can promote momentum investing and stock market bubbles.},
   author = {Stephen H. Penman},
   doi = {10.2308/ACCH.2003.17.S-1.77},
   issn = {08887993},
   issue = {SUPPL.},
   journal = {Accounting Horizons},
   pages = {77-96},
   title = {The quality of financial statements: Perspectives from the recent stock market bubble},
   volume = {17},
   year = {2003},
}
@article{Brown1999,
   abstract = {Accounting research frequently uses R2, for example, to measure value relevance. We show analytically that scale effects present in levels regressions increase R2, and this effect increases in the scale factor's coefficient of variation. Thus, between-sample comparisons of R2 are invalid, unless one controls for differences in the scale factor's coefficient of variation. Applying our analysis to prior research, we show that the documented increase in value relevance of accounting is attributable to increases in the coefficient of variation of the scale factor. Controlling for this effect, there has been a decline in value relevance, as measured by R2. © 1999 Elsevier Science B.V.},
   author = {Stephen Brown and Kin Lo and Thomas Lys},
   doi = {10.1016/S0165-4101(99)00023-3},
   issn = {0165-4101},
   issue = {2},
   journal = {Journal of Accounting and Economics},
   keywords = {C51,Capital markets,Econometric models,Equity valuation,Financial reporting,G10,G38,M41},
   month = {12},
   pages = {83-115},
   publisher = {North-Holland},
   title = {Use of R2 in accounting research: measuring changes in value relevance over the last four decades},
   volume = {28},
   year = {1999},
}
@article{Francis1999,
   abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.},
   author = {Jennifer Francis and Katherine Schipper},
   doi = {10.2307/2491412},
   issn = {00218456},
   issue = {2},
   journal = {Journal of Accounting Research},
   month = {23},
   pages = {319},
   publisher = {JSTOR},
   title = {Have Financial Statements Lost Their Relevance?},
   volume = {37},
   year = {1999},
}
@article{Valliere2007,
   abstract = {Findings are presented from a study of the cognitive behaviours of 57 venture capital investors in the early-stage technology sector during the 1998 – 2001 Internet bubble period. The inductive res...},
   author = {Dave Valliere and Rein Peterson},
   doi = {10.1080/1369106032000152452},
   issn = {14645343},
   issue = {1},
   journal = {http://dx.doi.org/10.1080/1369106032000152452},
   keywords = {Internet bubble,cognitive decision making model,escalating commitment,investment criteria,venture capitalists},
   pages = {1-22},
   publisher = { Taylor & Francis Ltd },
   title = {Inflating the bubble: examining dot-com investor behaviour},
   volume = {6},
   url = {https://www.tandfonline.com/doi/abs/10.1080/1369106032000152452},
   year = {2007},
}
@article{Ljungqvist2003,
   abstract = {IPO underpricing reached astronomical levels during 1999 and 2000. We show that the regime shift in initial returns and other elements of pricing behavior can be at least partially accounted for by marked changes in pre-IPO ownership structure and insider selling behavior over the period, which reduced key decision makers' incentives to control underpricing. After controlling for these changes, the difference in underpricing between 1999 and 2000 and the preceding three years is much reduced. Our results suggest that it was firm characteristics that were unique during the "dot-com bubble" and that pricing behavior followed from incentives created by these characteristics.},
   author = {Alexander Ljungqvist and William J. Wilhelm},
   doi = {10.1111/1540-6261.00543},
   issn = {1540-6261},
   issue = {2},
   journal = {The Journal of Finance},
   month = {4},
   pages = {723-752},
   publisher = {John Wiley & Sons, Ltd},
   title = {IPO Pricing in the Dot-com Bubble},
   volume = {58},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/1540-6261.00543 https://onlinelibrary.wiley.com/doi/abs/10.1111/1540-6261.00543 https://onlinelibrary.wiley.com/doi/10.1111/1540-6261.00543},
   year = {2003},
}
@article{Ofek2003,
   abstract = {This paper explores a model based on agents with heterogenous beliefs facing short sales restrictions, and its explanation for the rise, persistence, and eventual fall of Internet stock prices. First, we document substantial short sale restrictions for Internet stocks. Second, using data on Internet holdings and block trades, we show a link between heterogeneity and price effects for Internet stocks. Third, arguing that lockup expirations are a loosening of the short sale constraint, we document average, long-run excess returns as low as -33 percent for Internet stocks postlockup. We link the Internet bubble burst to the unprecedented level of lockup expirations and insider selling.},
   author = {Eli Ofek and Matthew Richardson},
   doi = {10.1111/1540-6261.00560},
   issn = {1540-6261},
   issue = {3},
   journal = {The Journal of Finance},
   month = {6},
   pages = {1113-1137},
   publisher = {John Wiley & Sons, Ltd},
   title = {DotCom Mania: The Rise and Fall of Internet Stock Prices},
   volume = {58},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/1540-6261.00560 https://onlinelibrary.wiley.com/doi/abs/10.1111/1540-6261.00560 https://onlinelibrary.wiley.com/doi/10.1111/1540-6261.00560},
   year = {2003},
}
@article{Ranganathan2018,
   abstract = {We identify temporal investor networks for Nokia stock by constructing networks from correlations between investor-specific net-volumes and analyze changes in the networks around dot-com bubble. The analysis is conducted separately for households, financial, and non-financial institutions. Our results indicate that spanning tree measures for households reflected the boom and crisis: the maximum spanning tree measures had a clear upward tendency in the bull markets when the bubble was building up, and, even more importantly, the minimum spanning tree measures pre-reacted the burst of the bubble. At the same time, we find less clear reactions in the minimal and maximal spanning trees of non-financial and financial institutions around the bubble, which suggests that household investors can have a greater herding tendency around bubbles.},
   author = {Sindhuja Ranganathan and Mikko Kivelä and Juho Kanniainen},
   doi = {10.1371/JOURNAL.PONE.0198807},
   isbn = {1111111111},
   issn = {1932-6203},
   issue = {6},
   journal = {PLOS ONE},
   keywords = {Algorithms,Built structures,Evolutionary rate,Finance,Financial markets,Graphs,Network analysis,Stock markets},
   month = {6},
   pages = {e0198807},
   pmid = {29897973},
   publisher = {Public Library of Science},
   title = {Dynamics of investor spanning trees around dot-com bubble},
   volume = {13},
   url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0198807},
   year = {2018},
}
@article{Yaga2019,
   abstract = {Blockchains are tamper evident and tamper resistant digital ledgers implemented in a distributed fashion (i.e., without a central repository) and usually without a central authority (i.e., a bank, company, or government). At their basic level, they enable a community of users to record transactions in a shared ledger within that community, such that under normal operation of the blockchain network no transaction can be changed once published. This document provides a high-level technical overview of blockchain technology. The purpose is to help readers understand how blockchain technology works.},
   author = {Dylan Yaga and Peter Mell and Nik Roby and Karen Scarfone},
   doi = {10.6028/NIST.IR.8202},
   keywords = {asymmetric-key cryptography,blockchain,consensus model,cryptocurrency,cryptographic hash function,data oracle,distributed consensus algorithm,distributed ledger,hard fork,proof of authority,proof of elapsed time,proof of identity,proof of stake,proof of work,round robin,smart contracts,soft fork},
   month = {6},
   title = {Blockchain Technology Overview},
   url = {http://arxiv.org/abs/1906.11078 http://dx.doi.org/10.6028/NIST.IR.8202},
   year = {2019},
}
@article{Zheng2017,
   abstract = {Blockchain, the foundation of Bitcoin, has received extensive attentions recently. Blockchain serves as an immutable ledger which allows transactions take place in a decentralized manner. Blockchain-based applications are springing up, covering numerous fields including financial services, reputation system and Internet of Things (IoT), and so on. However, there are still many challenges of blockchain technology such as scalability and security problems waiting to be overcome. This paper presents a comprehensive overview on blockchain technology. We provide an overview of blockchain architechture firstly and compare some typical consensus algorithms used in different blockchains. Furthermore, technical challenges and recent advances are briefly listed. We also lay out possible future trends for blockchain.},
   author = {Zibin Zheng and Shaoan Xie and Hongning Dai and Xiangping Chen and Huaimin Wang},
   doi = {10.1109/BIGDATACONGRESS.2017.85},
   isbn = {9781538619964},
   journal = {Proceedings - 2017 IEEE 6th International Congress on Big Data, BigData Congress 2017},
   keywords = {Blockchain,consensus,decentralization,scalability},
   month = {9},
   pages = {557-564},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {An Overview of Blockchain Technology: Architecture, Consensus, and Future Trends},
   year = {2017},
}
@book_section{Pilkington2016,
   author = {Marc Pilkington},
   doi = {10.4337/9781784717766.00019},
   isbn = {9781784717766},
   journal = {Research Handbooks on Digital Transformations},
   month = {9},
   pages = {225-253},
   publisher = {Edward Elgar Publishing Ltd.},
   title = {Blockchain technology: Principles and applications},
   year = {2016},
}
@article{Golosova2018,
   abstract = {The Blockchain is the newest and perspective technology in modern economy. This technology can help to solve different kind of problems in the industrial sphere, such as trust, transparency, security and reliability of data processing. In theory, the use of Blockchain technology shows great and positive results, but what can say about practice? In this paper the description of the Blockchain technology, and it advantages and disadvantages are analyzed. Many already implemented applications of Blockchain technology were studied, as well as affected success or problems factors during the implementations. This paper aim is to analyze conveniences and difficulties, related to the Blockchain integration and implementation in the different fields of modern industry.},
   author = {Julija Golosova and Andrejs Romanovs},
   doi = {10.1109/AIEEE.2018.8592253},
   isbn = {9781728119991},
   journal = {2018 IEEE 6th Workshop on Advances in Information, Electronic and Electrical Engineering, AIEEE 2018 - Proceedings},
   keywords = {Blockchain implementation success factors,Blockchain technology,Industrial cases},
   month = {12},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {The advantages and disadvantages of the blockchain technology},
   year = {2018},
}
@book{Swan2015,
   author = {Melanie Swan},
   edition = {1},
   isbn = {9781491920497},
   pages = {1-149},
   publisher = {O'Reilly and Associates},
   title = {Blockchain: Blueprint for a New Economy - Melanie Swan - Google Books},
   volume = {1},
   year = {2015},
}
@article{Nofer2017,
   author = {Michael Nofer and Peter Gomber and Oliver Hinz and Dirk Schiereck},
   doi = {10.1007/S12599-017-0467-3},
   issn = {18670202},
   issue = {3},
   journal = {Business and Information Systems Engineering},
   keywords = {Block chain,Blockchain,Business models,Digital currency,Disintegration},
   month = {6},
   pages = {183-187},
   publisher = {Gabler Verlag},
   title = {Blockchain},
   volume = {59},
   year = {2017},
}
@book{Meinel2020,
   author = {Christoph Meinel and Tatiana Gayvoronskaya},
   city = {Berlin, Heidelberg},
   doi = {10.1007/978-3-662-61916-2},
   edition = {1},
   isbn = {978-3-662-61915-5},
   pages = {1-136},
   publisher = {Springer Vieweg Berlin, Heidelberg},
   title = {Blockchain},
   volume = {1},
   url = {http://link.springer.com/10.1007/978-3-662-61916-2},
   year = {2020},
}
@book{VanHijfte2020,
   abstract = {… When we talk about blockchain, more often than not business professionals do not have a … duce blockchain to business professionals, specifically focusing on not just what blockchain …},
   author = {Stijn Van Hijfte},
   doi = {10.1007/978-1-4842-6137-8},
   edition = {1},
   journal = {Decoding Blockchain for Business},
   pages = {1-145},
   publisher = {Apress Berkeley, CA},
   title = {Decoding Blockchain for Business},
   year = {2020},
}
@article{Ghiro2021,
   abstract = {The use of the term blockchain is documented for disparate projects, from
cryptocurrencies to applications for the Internet of Things (IoT), and many
more. The concept of blockchain appears therefore blurred, as it is hard to
believe that the same technology can empower applications that have extremely
different requirements and exhibit dissimilar performance and security. This
position paper elaborates on the theory of distributed systems to advance a
clear definition of blockchain that allows us to clarify its role in the IoT.
This definition inextricably binds together three elements that, as a whole,
provide the blockchain with those unique features that distinguish it from
other distributed ledger technologies: immutability, transparency and
anonimity. We note however that immutability comes at the expense of remarkable
resource consumption, transparency demands no confidentiality and anonymity
prevents user identification and registration. This is in stark contrast to the
requirements of most IoT applications that are made up of resource constrained
devices, whose data need to be kept confidential and users to be clearly known.
Building on the proposed definition, we derive new guidelines for selecting the
proper distributed ledger technology depending on application requirements and
trust models, identifying common pitfalls leading to improper applications of
the blockchain. We finally indicate a feasible role of the blockchain for the
IoT: myriads of local, IoT transactions can be aggregated off-chain and then be
successfully recorded on an external blockchain as a means of public
accountability when required.},
   author = {Lorenzo Ghiro and Francesco Restuccia and Salvatore D ' Oro and Stefano Basagni and Tommaso Melodia and Leonardo Maccari and Renato Lo Cigno},
   doi = {10.48550/arxiv.2102.03750},
   month = {2},
   title = {What is a Blockchain? A Definition to Clarify the Role of the Blockchain in the Internet of Things},
   url = {https://arxiv.org/abs/2102.03750v1},
   year = {2021},
}
@article{Bahga2016,
   abstract = {Internet of Things (IoT) are being adopted
for industrial and manufacturing applications such as manufacturing automation,
remote machine diagnostics, prognostic health management of industrial machines
and supply chain management. Cloud-Based Manufacturing is a recent on-demand
model of manufacturing that is leveraging IoT technologies. While Cloud-Based
Manufacturing enables on-demand access to manufacturing resources, a trusted
intermediary is required for transactions between the users who wish to avail
manufacturing services. We present a decentralized, peer-to-peer platform
called BPIIoT for Industrial Internet of Things based on the Block chain
technology. With the use of Blockchain technology, the BPIIoT platform enables
peers in a decentralized, trustless, peer-to-peer network to interact with each
other without the need for a trusted intermediary.},
   author = {Arshdeep Bahga and Vijay K. Madisetti and Arshdeep Bahga and Vijay K. Madisetti},
   doi = {10.4236/JSEA.2016.910036},
   issn = {1945-3116},
   issue = {10},
   journal = {Journal of Software Engineering and Applications},
   keywords = {Blockchain,Cloud-Based Manufacturing,Internet of Things,Smart Contracts},
   month = {10},
   pages = {533-546},
   publisher = {Scientific Research Publishing},
   title = {Blockchain Platform for Industrial Internet of Things},
   volume = {9},
   url = {http://www.scirp.org/journal/PaperInformation.aspx?PaperID=71596 http://www.scirp.org/Journal/Paperabs.aspx?paperid=71596},
   year = {2016},
}
@article{Zheng2020,
   abstract = {Smart contract technology is reshaping conventional industry and business processes. Being embedded in blockchains, smart contracts enable the contractual terms of an agreement to be enforced automatically without the intervention of a trusted third party. As a result, smart contracts can cut down administration and save services costs, improve the efficiency of business processes and reduce the risks. Although smart contracts are promising to drive the new wave of innovation in business processes, there are a number of challenges to be tackled. This paper presents a survey on smart contracts. We first introduce blockchains and smart contracts. We then present the challenges in smart contracts as well as recent technical advances. We also compare typical smart contract platforms and give a categorization of smart contract applications along with some representative examples.},
   author = {Zibin Zheng and Shaoan Xie and Hong Ning Dai and Weili Chen and Xiangping Chen and Jian Weng and Muhammad Imran},
   doi = {10.1016/J.FUTURE.2019.12.019},
   issn = {0167-739X},
   journal = {Future Generation Computer Systems},
   keywords = {Blockchain,Cryptocurrency,Decentralization,Smart contract},
   month = {4},
   pages = {475-491},
   publisher = {North-Holland},
   title = {An overview on smart contracts: Challenges, advances and platforms},
   volume = {105},
   year = {2020},
}
@article{Hewa2021,
   abstract = {Blockchain is one of the disruptive technical innovation in the recent computing paradigm. Many applications already notoriously hard and complex are fortunate to ameliorate the service with the blessings of blockchain and smart contracts. The decentralized and autonomous execution with in-built transparency of blockchain based smart contracts revolutionize most of the applications with optimum and effective functionality. The paper explores the significant applications which already benefited from the smart contracts. We also highlight the future potential of the blockchain based smart contracts in these applications perspective.},
   author = {Tharaka Hewa and Mika Ylianttila and Madhusanka Liyanage},
   doi = {10.1016/J.JNCA.2020.102857},
   issn = {1084-8045},
   journal = {Journal of Network and Computer Applications},
   keywords = {Applications,Blockchain,Corda,DLT,Ethereum,Hyperledger Fabric,Smart contracts,Stellar},
   month = {3},
   pages = {102857},
   publisher = {Academic Press},
   title = {Survey on blockchain based smart contracts: Applications, opportunities and challenges},
   volume = {177},
   year = {2021},
}
@web_page{Szabo1994,
   author = {Nick Szabo},
   title = {Smart Contracts},
   url = {https://www.fon.hum.uva.nl/rob/Courses/InformationInSpeech/CDROM/Literature/LOTwinterschool2006/szabo.best.vwh.net/smart.contracts.html},
   year = {1994},
}
@article{Chohan2021,
   abstract = {Non-Fungible Tokens (NFTs) have garnered remarkable investor attention recently, with some NFTs securing selling prices that may have seemed unthinkable for a non-fungible virtual asset. This raises fascinating questions about "value" and "scarcity" with respect to blockchain technology, through a prism of non-fungibility of a digital asset, and this paper aims to draw attention to these questions insofar as they may shape an alternative space of blockchain development and exchange going forward.},
   author = {Usman W. Chohan},
   doi = {10.2139/SSRN.3822743},
   journal = {SSRN Electronic Journal},
   keywords = {Blockchain,Cryptocurrencies,Ethereum,NFT,Non-Fungible Tokens,Non-Fungible Tokens: Blockchains,SSRN,Scarcity,Usman W. Chohan,and Value},
   month = {3},
   publisher = {Elsevier BV},
   title = {Non-Fungible Tokens: Blockchains, Scarcity, and Value},
   url = {https://papers.ssrn.com/abstract=3822743},
   year = {2021},
}
@article{Valeonti2021,
   abstract = {Non-fungible tokens (NFTs) make it technically possible for digital assets to be owned and traded, introducing the concept of scarcity in the digital realm for the first time. Resulting from this technical development, this paper asks the question, do they provide an opportunity for fundraising for galleries, libraries, archives and museums (GLAM), by selling ownership of digital copies of their collections? Although NFTs in their current format were first invented in 2017 as a means for game players to trade virtual goods, they reached the mainstream in 2021, when the auction house Christie’s held their first-ever sale exclusively for an NFT of a digital image, that was eventually sold for a record 69 million USD. The potential of NFTs to generate significant revenue for artists and museums by selling effectively a cryptographically signed copy of a digital image (similar to real-world limited editions, which are signed and numbered copies of a given artwork), has sparked the interest of the financially deprived museum and heritage sector with world-renowned institutions such as the Uffizi Gallery and the Hermitage Museum, having already employed NFTs in order to raise funds. Concerns surrounding the environmental impact of blockchain technology and the rise of malicious projects, exploiting previously digitised heritage content made available through OpenGLAM licensing, have attracted criticism over the speculative use of the technology. In this paper, we present the current state of affairs in relation to NFTs and the cultural heritage sector, identifying challenges, whilst highlighting opportunities that they create for revenue generation, in order to help address the ever-increasing financial challenges of galleries and museums.},
   author = {Foteini Valeonti and Antonis Bikakis and Melissa Terras and Chris Speed and Andrew Hudson-Smith and Konstantinos Chalkias},
   doi = {10.3390/APP11219931},
   issn = {2076-3417},
   issue = {21},
   journal = {Applied Sciences 2021, Vol. 11, Page 9931},
   keywords = {OpenGLAM,digitised collections,fungible tokens,museum funding,non},
   month = {10},
   pages = {9931},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Crypto Collectibles, Museum Funding and OpenGLAM: Challenges, Opportunities and the Potential of Non-Fungible Tokens (NFTs)},
   volume = {11},
   url = {https://www.mdpi.com/2076-3417/11/21/9931/htm https://www.mdpi.com/2076-3417/11/21/9931},
   year = {2021},
}
@article{Wang2021,
   abstract = {The Non-Fungible Token (NFT) market is mushrooming in recent years. The
concept of NFT originally comes from a token standard of Ethereum, aiming to
distinguish each token with distinguishable signs. This type of token can be
bound with virtual/digital properties as their unique identifications. With
NFTs, all marked properties can be freely traded with customized values
according to their ages, rarity, liquidity, etc. It has greatly stimulated the
prosperity of the decentralized application (DApp) market. At the time of
writing (May 2021), the total money used on completed NFT sales has reached
$34,530,649.86$ USD. The thousandfold return on its increasing market draws
huge attention worldwide. However, the development of the NFT ecosystem is
still in its early stage, and the technologies of NFTs are pre-mature.
Newcomers may get lost in their frenetic evolution due to the lack of
systematic summaries. In this technical report, we explore the NFT ecosystems
in several aspects. We start with an overview of state-of-the-art NFT
solutions, then provide their technical components, protocols, standards, and
desired proprieties. Afterward, we give a security evolution, with discussions
on the perspectives of their design models, opportunities, and challenges. To
the best of our knowledge, this is the first systematic study on the current
NFT ecosystems.},
   author = {Qin Wang and Rujia Li and Qi Wang and Shiping Chen},
   doi = {10.48550/arxiv.2105.07447},
   keywords = {App ·,Blockchain · NFT · D,Smart contract},
   month = {5},
   title = {Non-Fungible Token (NFT): Overview, Evaluation, Opportunities and Challenges},
   url = {https://arxiv.org/abs/2105.07447v3},
   year = {2021},
}
@article{Granstrand2020,
   abstract = {The concept of innovation ecosystems has become popular during the last 15 years, leading to a debate regarding its relevance and conceptual rigor, not the least in this journal. The purpose of this article is to review received definitions of innovation ecosystems and related concepts and to propose a synthesized definition of an innovation ecosystem. The conceptual analysis identifies an unbalanced focus on complementarities, collaboration, and actors in received definitions, and among other things proposes the additional inclusion of competition, substitutes, and artifacts in conceptualizations of innovation ecosystems, leading to the following definition: An innovation ecosystem is the evolving set of actors, activities, and artifacts, and the institutions and relations, including complementary and substitute relations, that are important for the innovative performance of an actor or a population of actors. This definition is compatible with related conceptualizations of innovation systems and natural ecosystems, and the validity of it is illustrated with three empirical examples of innovation ecosystems.},
   author = {Ove Granstrand and Marcus Holgersson},
   doi = {10.1016/J.TECHNOVATION.2019.102098},
   issn = {0166-4972},
   journal = {Technovation},
   month = {2},
   pages = {102098},
   publisher = {Elsevier},
   title = {Innovation ecosystems: A conceptual review and a new definition},
   volume = {90-91},
   year = {2020},
}
@article{Baregheh2009,
   abstract = {Purpose - This paper aims to undertake a content analysis of extant definitions of "innovation" as a basis for proposing an integrative definition of organizational "innovation". Design/methodology/approach - A literature review was used to generate a representative pool of definitions of organizational innovation, including definitions from the different disciplinary literatures of economics, innovation and entrepreneurship, business and management, and technology, science and engineering. A content analysis of these definitions was conducted in order to surface the key attributes mentioned in the definitions, and to profile the descriptors used in relation to each attribute. Findings - The key attributes in the paper present in definitions were identified as: nature of innovation; type of innovation; stages of innovation, social context; means of innovation; and aim of innovation. These attributes are defined, descriptors assigned to them, and both a diagrammatic definition and a textual definition of organizational innovation are proposed. Originality/value - As a concept that is owned and discussed by many business disciplines, "innovation" has many different definitions that align with the dominant paradigm of the respective disciplines. Building on these diverse definitions, this paper proposes a general and integrative definition of organizational "innovation" that encompasses the different perspectives on, and aspects of, innovation, and captures its essence. © Emerald Group Publishing Limited.},
   author = {Anahita Baregheh and Jennifer Rowley and Sally Sambrook},
   doi = {10.1108/00251740910984578/FULL/XML},
   issn = {00251747},
   issue = {8},
   journal = {Management Decision},
   keywords = {Innovation,Organizational innovation,United Kingdom},
   month = {9},
   pages = {1323-1339},
   publisher = {Emerald Group Publishing Limited},
   title = {Towards a multidisciplinary definition of innovation},
   volume = {47},
   year = {2009},
}
@book_section{Oslo2018,
   author = {OECD and Eurostat},
   doi = {https://doi.org/10.1787/9789264304604-en.},
   edition = {4},
   journal = {The Measurement of Scientific, Technological and Innovation Activities},
   pages = {1-256},
   publisher = {OECD Publishing},
   title = {Oslo Manual 2018: Guidelines for Collecting, Reporting and Using Data on Innovation, 4th Edition},
   url = {https://www.oecd.org/science/oslo-manual-2018-9789264304604-en.htm},
   year = {2018},
}
@article{Paladino2007,
   abstract = {The notion of producing innovations and achieving new product success has received a great deal of attention. Though many have investigated these effects in marketing and various fields within management, there has been little cross-fertilization between fields of study to explain the basis for this superior performance. Though research has examined the resource-based view (RBV) and market orientation individually, none has evaluated and compared their effect on firm innovation and new product success in one study. Furthermore, although empirical work has been conducted between market orientation and organizational learning, comparatively less research has been conducted to evaluate the relationship between organizational learning and the RBV to examine their combined effects on a firm's ability to innovate and succeed. Subsequently, the purpose of the present article is to investigate whether a focus on the customer (i.e., market orientation) or the firm (i.e., RBV) will drive the ability to (1) innovate within the firm and (2) succeed in terms of new product success, financial performance, market share, and customer value. The present article examines the relationship between organizational learning and the RBV and market orientation. It presents an empirically testable framework that investigates the relationship that RBV and market orientation have with performance outcomes. Data were collected from 249 senior executives. LISREL was applied to evaluate the relationships. Confirmatory factor analysis and related techniques were applied to assess the robustness of the measures used. Findings show that organizational learning is strongly associated with market orientation, which in turn impacts various performance outcomes including customer value. The RBV had a significant relationship with new product success. These results suggest that managers seeking innovation and new product success should focus less on the provision of customer value. Instead they should look toward developing their resources within the firm, including investing in human resources, to ultimately provide value to the firm. Findings indicate that this unique offering - innovations - will have an indirect effect on customer value and financial performance. In contrast, those in pursuit of positive financial performance and customer value should focus on the development of market orientation. Even though this will not necessarily lead to the development of innovative processes and new product success according to the present study, this approach may lead to a greater market share in the long term. This article reviews theoretical and managerial implications in more depth, providing an impetus for further research. © 2007 Product Development & Management Association.},
   author = {Angela Paladino},
   doi = {10.1111/J.1540-5885.2007.00270.X},
   issn = {1540-5885},
   issue = {6},
   journal = {Journal of Product Innovation Management},
   month = {11},
   pages = {534-553},
   publisher = {John Wiley & Sons, Ltd},
   title = {Investigating the Drivers of Innovation and New Product Success: A Comparison of Strategic Orientations*},
   volume = {24},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-5885.2007.00270.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5885.2007.00270.x https://onlinelibrary.wiley.com/doi/10.1111/j.1540-5885.2007.00270.x},
   year = {2007},
}
@article{Fellnhofer2017,
   abstract = {Based on Stevenson's (1983) modified conceptualisation of entrepreneurship, this study illuminates the set of opportunity-based management practices across organisational levels. This empirical study of 301 employees from four sustainable-oriented organisations contributes to an understanding of the harmonising nature of sustainable entrepreneurship and innovation. Overall, Stevenson's construct dimensions include strategic orientation, resource orientation, management structure, reward philosophy, growth orientation and entrepreneurial culture to determine a firm's level of entrepreneurial orientation. The present study confirms the widespread perception that these constructs have a significant, positive impact on a firm's innovation success. The results indicate that these dimensions are significant and positive predictors of perceived innovation success within sustainable businesses, thus expanding entrepreneurial theory with findings of significant impact on the success of innovation. This study's results also add to the research on entrepreneurship–innovation interplays. From a practical perspective, Stevenson's multilevel entrepreneurial approach offers drivers of innovation success in sustainable businesses. Thus, Stevenson's concept of entrepreneurship could be used as a predicting indicator to promote sustainable innovation success throughout different company levels. As this is the first contribution with such a scope, further investigation is required. This article opens a research stream for scholars to further evaluate sustainable entrepreneurship–innovation relationships.},
   author = {Katharina Fellnhofer},
   doi = {10.1016/J.JCLEPRO.2017.08.197},
   issn = {0959-6526},
   journal = {Journal of Cleaner Production},
   keywords = {Innovation success,Multi-level entrepreneurial behaviour,Opportunity-based behaviour,Sustainable businesses},
   month = {11},
   pages = {1534-1545},
   publisher = {Elsevier},
   title = {Drivers of innovation success in sustainable businesses},
   volume = {167},
   year = {2017},
}
@article{Phillips2011b,
   abstract = {A recursive test procedure is suggested that provides a mechanism for testing explosive behavior, date stamping the origination and collapse of economic exuberance, and providing valid confidence intervals for explosive growth rates. The method involves the recursive implementation of a right-side unit root test and a sup test, both of which are easy to use in practical applications, and some new limit theory for mildly explosive processes. The test procedure is shown to have discriminatory power in detecting periodically collapsing bubbles, thereby overcoming a weakness in earlier applications of unit root tests for economic bubbles. An empirical application to the Nasdaq stock price index in the 1990s provides confirmation of explosiveness and date stamps the origination of financial exuberance to mid-1995, prior to the famous remark in December 1996 by Alan Greenspan about irrational exuberance in the financial market, thereby giving the remark empirical content. How do we know when irrational exuberance has unduly escalated asset values? (Alan Greenspan, 1996) Experience can be a powerful teacher. The rise and fall of internet stocks, which created and then destroyed \$8 trillion of shareholder wealth, has led a new generation of economists to acknowledge that bubbles can occur.(Alan Krueger, 2005) © (2011) by the Economics Department of the University of Pennsylvania and the Osaka University Institute of Social and Economic Research Association.},
   author = {Peter C.B. Phillips and Yangru Wu and Jun Yu},
   doi = {10.1111/J.1468-2354.2010.00625.X},
   issn = {1468-2354},
   issue = {1},
   journal = {International Economic Review},
   month = {2},
   pages = {201-226},
   publisher = {John Wiley & Sons, Ltd},
   title = {EXPLOSIVE BEHAVIOR IN THE 1990s NASDAQ: WHEN DID EXUBERANCE ESCALATE ASSET VALUES?*},
   volume = {52},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1468-2354.2010.00625.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2354.2010.00625.x https://onlinelibrary.wiley.com/doi/10.1111/j.1468-2354.2010.00625.x},
   year = {2011},
}
@article{Phillips2015a,
   abstract = {Recent work on econometric detection mechanisms has shown the effectiveness of recursive procedures in identifying and dating financial bubbles in real time. These procedures are useful as warning alerts in surveillance strategies conducted by central banks and fiscal regulators with real-time data. Use of these methods over long historical periods presents a more serious econometric challenge due to the complexity of the nonlinear structure and break mechanisms that are inherent in multiple-bubble phenomena within the same sample period. To meet this challenge, this article develops a new recursive flexible window method that is better suited for practical implementation with long historical time series. The method is a generalized version of the sup augmented Dickey-Fuller (ADF) test of Phillips et al. ("Explosive behavior in the 1990s NASDAQ: When did exuberance escalate asset values?" International Economic Review 52 (2011), 201-26; PWY) and delivers a consistent real-time date-stamping strategy for the origination and termination of multiple bubbles. Simulations show that the test significantly improves discriminatory power and leads to distinct power gains when multiple bubbles occur. An empirical application of the methodology is conducted on S&P 500 stock market data over a long historical period from January 1871 to December 2010. The new approach successfully identifies the well-known historical episodes of exuberance and collapses over this period, whereas the strategy of PWY and a related cumulative sum (CUSUM) dating procedure locate far fewer episodes in the same sample range.},
   author = {Peter C.B. Phillips and Shuping Shi and Jun Yu},
   doi = {10.1111/IERE.12132},
   issn = {1468-2354},
   issue = {4},
   journal = {International Economic Review},
   month = {11},
   pages = {1043-1078},
   publisher = {John Wiley & Sons, Ltd},
   title = {TESTING FOR MULTIPLE BUBBLES: HISTORICAL EPISODES OF EXUBERANCE AND COLLAPSE IN THE S\&P 500},
   volume = {56},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/iere.12132 https://onlinelibrary.wiley.com/doi/abs/10.1111/iere.12132 https://onlinelibrary.wiley.com/doi/10.1111/iere.12132},
   year = {2015},
}
@article{Phillips2015b,
   abstract = {This article provides the limit theory of real-time dating algorithms for bubble detection that were suggested in Phillips, Wu, and Yu (PWY; International Economic Review 52 [2011], 201-26) and in a companion paper by the present authors (Phillips, Shi, and Yu, 2015; PSY; International Economic Review 56 [2015a], 1099-1134. Bubbles are modeled using mildly explosive bubble episodes that are embedded within longer periods where the data evolve as a stochastic trend, thereby capturing normal market behavior as well as exuberance and collapse. Both the PWY and PSY estimates rely on recursive right-tailed unit root tests (each with a different recursive algorithm) that may be used in real time to locate the origination and collapse dates of bubbles. Under certain explicit conditions, the moving window detector of PSY is shown to be a consistent dating algorithm even in the presence of multiple bubbles. The other algorithms are consistent detectors for bubbles early in the sample and, under stronger conditions, for subsequent bubbles in some cases. These asymptotic results and accompanying simulations guide the practical implementation of the procedures. They indicate that the PSY moving window detector is more reliable than the PWY strategy, sequential application of the PWY procedure, and the CUSUM procedure.},
   author = {Peter C.B. Phillips and Shuping Shi and Jun Yu},
   doi = {10.1111/IERE.12131},
   issn = {1468-2354},
   issue = {4},
   journal = {International Economic Review},
   month = {11},
   pages = {1079-1134},
   publisher = {John Wiley & Sons, Ltd},
   title = {TESTING FOR MULTIPLE BUBBLES: LIMIT THEORY OF REAL-TIME DETECTORS},
   volume = {56},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1111/iere.12131 https://onlinelibrary.wiley.com/doi/abs/10.1111/iere.12131 https://onlinelibrary.wiley.com/doi/10.1111/iere.12131},
   year = {2015},
}
@article{Eickhoff2018,
   author = {Matthias Eickhoff and Runhild Wieneke},
   journal = {Hawaii International Conference on System Sciences 2018 (HICSS-51)},
   month = {1},
   title = {Understanding Topic Models in Context: A Mixed-Methods Approach to the Meaningful Analysis of Large Document Collections},
   url = {https://aisel.aisnet.org/hicss-51/da/data_text_web_mining/2},
   year = {2018},
}
@article{Daenekindt2020,
   abstract = {Parallel to the increasing level of maturity of the field of research on higher education, an increasing number of scholarly works aims at synthesising and presenting overviews of the field. We identify three important pitfalls these previous studies struggle with, i.e. a limited scope, a lack of a content-related analysis, and/or a lack of an inductive approach. We take these limitations into account by analysing the abstracts of 16,928 articles on higher education between 1991 and 2018. To investigate this huge collection of texts, we apply topic models, which are a collection of automatic content analysis methods that allow to map the structure of large text data. After an in-depth discussion of the topics differentiated by our model, we study how these topics have evolved over time. In addition, we analyse which topics tend to co-occur in articles. This reveals remarkable gaps in the literature which provides interesting opportunities for future research. Furthermore, our analysis corroborates the claim that the field of research on higher education consists of isolated ‘islands’. Importantly, we find that these islands drift further apart because of a trend of specialisation. This is a bleak finding, suggesting the (further) disintegration of our field.},
   author = {Stijn Daenekindt and Jeroen Huisman},
   doi = {10.1007/S10734-020-00500-X/FIGURES/3},
   issn = {1573174X},
   issue = {3},
   journal = {Higher Education},
   keywords = {Automated text analysis,Bibliometrics,Big data analysis,Content analysis,Correlated topic models,Higher education research,Research specialization,Systematic review},
   month = {9},
   pages = {571-587},
   publisher = {Springer},
   title = {Mapping the scattered field of research on higher education. A correlated topic model of 17,000 articles, 1991–2018},
   volume = {80},
   url = {https://link.springer.com/article/10.1007/s10734-020-00500-x},
   year = {2020},
}
@article{Bai2021,
   abstract = {Maritime transport is considered as the lynchpin of global trade. In the past decades, a large number of academic articles in the maritime transport field have been published. This study aims to provide a comprehensive review of the development of maritime transport research. A structural topic model (STM) is adopted to analyze the research themes and trends in the maritime literature. STM is a text mining-based methodology to uncover main topics from large-scale unstructured textual data. In total, 3199 articles published between Jan 1991 and Aug 2020 were collected and analyzed. The results show that the major academic concerns of maritime transport are related to port management, container operations and liner shipping management. The overall research trends have shifted from regulations and policy management to efficient, integrated and sustainable maritime transport over the past few decades. The main research topics and emerging trends discovered from STM can facilitate researchers, funding groups and policymakers for identifying contemporary research issues and making more informed decisions.},
   author = {Xiwen Bai and Xiunian Zhang and Kevin X. Li and Yaoming Zhou and Kum Fai Yuen},
   doi = {10.1016/J.TRANPOL.2020.12.013},
   issn = {0967-070X},
   journal = {Transport Policy},
   keywords = {Maritime transport,Port,Research trends,Shipping,Structural topic model,Text mining},
   month = {3},
   pages = {11-24},
   publisher = {Pergamon},
   title = {Research topics and trends in the maritime transport: A structural topic model},
   volume = {102},
   year = {2021},
}
@article{Blei2003,
   abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
   author = {David M Blei and Andrew Y Ng and Jordan@cs Berkeley Edu},
   doi = {10.5555/944919.944937},
   journal = {Journal of Machine Learning Research},
   pages = {993-1022},
   title = {Latent Dirichlet Allocation Michael I. Jordan},
   volume = {3},
   year = {2003},
}
@article{Blei2012,
   author = {David M. Blei},
   doi = {10.1145/2133806.2133826},
   issn = {00010782},
   issue = {4},
   journal = {Communications of the ACM},
   month = {4},
   pages = {77-84},
   title = {Probabilistic topic models},
   volume = {55},
   year = {2012},
}
@inproceedings{HanLau2012,
   abstract = {We present a novel topic modelling-based methodology to track emerging events in microblogs such as Twitter. Our topic model has an in-built update mechanism based on time slices and implements a dynamic vocabulary. We first show that the method is robust in detecting events using a range of datasets with injected novel events, and then demonstrate its application in identifying trending topics in Twitter.},
   author = {J Han Lau and Nigel Collier and TImoth Baldwin},
   city = {Mumbai, India},
   journal = {Proceedings of COLING 2012},
   keywords = {Online Processing 1519,Topic Evolution,Topic Model,Trend Detection,Twitter},
   month = {12},
   pages = {1519-1534},
   publisher = {The COLING 2012 Organizing Committee},
   title = {On-line Trend Analysis with Topic Models: \#twitter trends detection topic model online},
   url = {http://twendr.com/},
   year = {2012},
}
@article{Battisti2015,
   abstract = {Topic models are a well known clustering approach for textual data, which provides promising applications in the bibliometric context for the purpose of discovering scientific topics and trends in a corpus of scientific publications. However, topic models per se provide poorly descriptive metadata featuring the discovered clusters of publications and they are not related to the other important metadata usually available with publications, such as authors affiliation, publication venue, and publication year. In this paper, we propose a methodological approach to topic modeling and post-processing of topic models results to the end of describing in depth a field of research over time. In particular, we work on a selection of publications from the international statistical literature, we propose an approach that allows us to identify sophisticated topic descriptors, and we analyze the links between topics and their temporal evolution.},
   author = {Francesca De Battisti and Alfio Ferrara and Silvia Salini},
   doi = {10.1007/S11192-015-1554-1/TABLES/9},
   issn = {15882861},
   issue = {2},
   journal = {Scientometrics},
   keywords = {Clustering,Probabilistic topic models,Scientometrics,Text mining},
   month = {5},
   pages = {413-433},
   publisher = {Kluwer Academic Publishers},
   title = {A decade of research in statistics: a topic model approach},
   volume = {103},
   url = {https://link.springer.com/article/10.1007/s11192-015-1554-1},
   year = {2015},
}
@article{Linton2017,
   abstract = {Cryptocurrencies are more and more used in official cash flows and exchange of goods. Bitcoin and the underlying blockchain technology have been looked at by big companies that are adopting and investing in this technology. The CRIX Index of cryptocurrencies...},
   author = {M. Linton and E. G. S. Teo and E. Bommes and C. Y. Chen and Wolfgang Karl Härdle},
   doi = {10.1007/978-3-662-54486-0_18},
   pages = {355-372},
   publisher = {Springer, Berlin, Heidelberg},
   title = {Dynamic Topic Modelling for Cryptocurrency Community Forums},
   url = {https://link.springer.com/chapter/10.1007/978-3-662-54486-0_18},
   year = {2017},
}
@article{Etaiwi2017,
   abstract = {Online reviews become a valuable source of information that indicate the overall opinion about products and services, which affect customer's decision to purchase a product or service. Since not all online reviews and comments are truthful, it is important to detect fake and poison reviews. Many machine learning techniques could be applied to detect spam reviews by extracting a useful features from review's text using Natural Language Processing (NLP). Many types of features could be used in this manor such as linguistic features, Word Count, n-gram feature sets and number of pronouns. In order to extract such features, many types of preprocessing steps could be performed before applying the classification method, this steps may include POS tagging, n-gram term frequencies, stemming, stop word and punctuation marks filtering, etc. this preprocessing steps may affect the overall accuracy of the review spam detection task. In this research, we will investigate the effects of preprocessing steps on the accuracy of reviews spam detection. Different machine learning algorithms will be applied such as Support Victor Machine (SVM) and Naïve Bayes (NB), and a labeled dataset of Hotels reviews will be analyze and process. The efficiency will be evaluated according to many evaluation measures such as: precision, recall and accuracy. Peer-review under responsibility of the Conference Program Chairs.},
   author = {Wael Etaiwi and Ghazi Naymat},
   doi = {10.1016/J.PROCS.2017.08.368},
   issn = {1877-0509},
   journal = {Procedia Computer Science},
   keywords = {Bag-of-Words,feature selection,machine learning,preprocessing,spam reviews},
   month = {1},
   pages = {273-279},
   publisher = {Elsevier},
   title = {The Impact of applying Different Preprocessing Steps on Review Spam Detection},
   volume = {113},
   year = {2017},
}
@article{Yogish2019,
   abstract = {In modern age of information explosion, every day millions of gigabytes of data are generated in the form of documents, web pages, e-mail, social media text, blogs etc., so importance of effective and efficient Natural Language Processing techniques become crucial for an information retrieval system, text summarization, sentiment analysis, information extraction, named entity recognition, relationship extraction, social media monitoring, text mining, language translation program, and question answering system. Natural Language Processing is a computational technique applies different levels of linguistic analysis for representing natural language into a useful representation for further processing. NLP is recognized as a challenging task in computer science and artificial intelligence because understanding human natural language is not only depends on the words but how those words are linked together to form precise meaning is also considered. Regardless of language being one of the easiest concepts for human to learn, but for training computers to understand natural language is a difficult task due to the ambiguity of language syntax and semantics. Natural Language processing techniques involves processing documents or text which reduces storage space and also reduces the size of index and understanding the given information which satisfies user’s need. NLP techniques improve the performance of the information retrieval efficiency and effective documentation processes. Common dialect handling procedures incorporates tokenization, stop word expulsion, stemming, lemmatization, parts of discourse labeling, lumping and named substance recognizer which enhances execution of NLP applications. The Natural Language Toolkit is the best possible solution for learning the ropes of NLP domain. NLTK, a collection of application packages which encourage researchers and learners in natural language processing, computational linguistics and artificial intelligence.},
   author = {Deepa Yogish and T. N. Manjunath and Ravindra S. Hegadi},
   doi = {10.1007/978-981-13-9187-3_53/FIGURES/14},
   isbn = {9789811391866},
   issn = {18650937},
   journal = {Communications in Computer and Information Science},
   keywords = {Artificial Intelligence (AI),Information Retrieval (IR),Natural Language Processing (NLP),Natural Language Tool Kit (NLTK)},
   pages = {589-606},
   publisher = {Springer Verlag},
   title = {Review on Natural Language Processing Trends and Techniques Using NLTK},
   volume = {1037},
   url = {https://link.springer.com/chapter/10.1007/978-981-13-9187-3_53},
   year = {2019},
}
@article{Plisson2004,
   author = {Joël Plisson and Joël Plisson and Nada Lavrac and Dunja Mladenic},
   journal = {PROCEEDINGS OF IS04},
   title = {A rule based approach to word lemmatization},
   url = {http://130.203.136.95/viewdoc/summary?doi=10.1.1.646.9308},
   year = {2004},
}
@article{Gan2021,
   abstract = {This study constructs a comprehensive index to effectively judge the optimal number of topics in the LDA topic model. Based on the requirements for selecting the number of topics, a comprehensive judgment index of perplexity, isolation, stability, and coincidence is constructed to select the number of topics. This method provides four advantages to selecting the optimal number of topics: (1) good predictive ability, (2) high isolation between topics, (3) no duplicate topics, and (4) repeatability. First, we use three general datasets to compare our proposed method with existing methods, and the results show that the optimal topic number selection method has better selection results. Then, we collected the patent policies of various provinces and cities in China (excluding Hong Kong, Macao, and Taiwan) as datasets. By using the optimal topic number selection method proposed in this study, we can classify patent policies well.},
   author = {Jingxian Gan and Yong Qi},
   doi = {10.3390/E23101301},
   issn = {1099-4300},
   issue = {10},
   journal = {Entropy 2021, Vol. 23, Page 1301},
   keywords = {LDA,optimal number of topics,patent policy,topic model},
   month = {10},
   pages = {1301},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Selection of the Optimal Number of Topics for LDA Topic Model—Taking Patent Policy Analysis as an Example},
   volume = {23},
   url = {https://www.mdpi.com/1099-4300/23/10/1301/htm https://www.mdpi.com/1099-4300/23/10/1301},
   year = {2021},
}
@article{Arun2010,
   abstract = {It is important to identify the "correct" number of topics in mechanisms like Latent Dirichlet Allocation(LDA) as they determine the quality of features that are presented as features for classifiers like SVM. In this work we propose a measure to identify the correct number of topics and offer empirical evidence in its favor in terms of classification accuracy and the number of topics that are naturally present in the corpus. We show the merit of the measure by applying it on real-world as well as synthetic data sets(both text and images). In proposing this measure, we view LDA as a matrix factorization mechanism, wherein a given corpus C is split into two matrix factors M1 and M2 as given by Cd*w = M1d*t × Qt*w. Where d is the number of documents present in the corpus and w is the size of the vocabulary. The quality of the split depends on "t", the right number of topics chosen. The measure is computed in terms of symmetric KL-Divergence of salient distributions that are derived from these matrix factors. We observe that the divergence values are higher for non-optimal number of topics - this is shown by a 'dip' at the right value for 't'. © 2010 Springer-Verlag Berlin Heidelberg.},
   author = {R. Arun and V. Suresh and C. E.Veni Madhavan and M. Narasimha Murty},
   doi = {10.1007/978-3-642-13657-3_43/COVER},
   isbn = {3642136567},
   issn = {03029743},
   issue = {PART 1},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {LDA Topic SVD KL-Divergence},
   pages = {391-402},
   publisher = {Springer, Berlin, Heidelberg},
   title = {On finding the natural number of topics with Latent Dirichlet Allocation: Some observations},
   volume = {6118 LNAI},
   url = {https://link.springer.com/chapter/10.1007/978-3-642-13657-3_43},
   year = {2010},
}
@article{Roeder2015,
   abstract = {Quantifying the coherence of a set of statements is a long standing problem with many potential applications that has attracted researchers from different sciences. The special case of measuring coherence of topics has been recently studied to remedy the problem that topic models give no guar-anty on the interpretablity of their output. Several benchmark datasets were produced that record human judgements of the interpretability of topics. We are the first to propose a framework that allows to construct existing word based coherence measures as well as new ones by combining elementary components. We conduct a systematic search of the space of coherence measures using all publicly available topic relevance data for the evaluation. Our results show that new combinations of components outperform existing measures with respect to correlation to human ratings. Finally, we outline how our results can be transferred to further applications in the context of text mining, information retrieval and the world wide web.},
   author = {Michael Röder and Andreas Both and Alexander Hinneburg},
   city = {New York, NY, USA},
   doi = {10.1145/2684822},
   isbn = {9781450333177},
   journal = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining},
   keywords = {[Document representation]: Document topic models General Terms Measurement Keywords topic evaluation,topic coherence,topic model},
   publisher = {ACM},
   title = {Exploring the Space of Topic Coherence Measures},
   url = {http://dx.doi.org/10.1145/2684822.2685324.},
   year = {2015},
}
@article{Hasan2021,
   abstract = {Feature extraction is one of the challenging works in the Machine Learning (ML) arena. The more features one able to extract correctly, the more accurate knowledge one can exploit from data. Latent Dirichlet Allocation (LDA) is a form of topic modeling used to extract features from text data. But finding the optimal number of topics (on which success of LDA depends on) is tremendous challenging, especially if there is no prior knowledge about the data. Some studies suggest perplexity; some are Rate of Perplexity Change (RPC); some suggest coherence as a method to find an optimal number of a topic for achieving both of accuracy and less processing time for LDA. In this study, the authors propose two new methods named Normalized Absolute Coherence (NAC) and Normalized Absolute Perplexity (NAP) for predicting the optimal number of topics. The authors run highly standard ML experiments to measure and compare the reliability of existing methods (perplexity, coherence, RPC) and proposed NAC and NAP in searching for an optimal number of topics in LDA. The study successfully proves and suggests that NAC and NAP work better than existing methods. This investigation also suggests that perplexity, coherence, and RPC are sometimes distracting and confusing to estimate the optimal number of topics.},
   author = {Mahedi Hasan and Anichur Rahman and Md Razaul Karim and Md Saikat Islam Khan and Md Jahidul Islam},
   doi = {10.1007/978-981-33-4673-4_27/FIGURES/7},
   isbn = {9789813346727},
   issn = {21945365},
   journal = {Advances in Intelligent Systems and Computing},
   keywords = {Big data,Coherence,Feature extraction,Information retrieval,LDA,Machine learning,Perplexity,Text mining,Topic modelling},
   pages = {341-354},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Normalized approach to find optimal number of topics in latent dirichlet allocation (lda)},
   volume = {1309},
   url = {https://link.springer.com/chapter/10.1007/978-981-33-4673-4_27},
   year = {2021},
}
@inproceedings{Chang2009,
   author = {Jonathan Chang and Sean Gerrish and Chong Wang and Jordan Boyd-Graber and David Blei},
   journal = {Advances in Neural Information Processing Systems},
   publisher = {Curran Associates, Inc.},
   title = {Reading Tea Leaves: How Humans Interpret Topic Models},
   url = {https://www.semanticscholar.org/paper/Reading-Tea-Leaves%3A-How-Humans-Interpret-Topic-Chang-Boyd-Graber/edd0aec78e53c08c90305e7a1234c2644d8f104a},
   year = {2009},
}
@article{Sievert2014,
   abstract = {We present LDAvis, a web-based interactive visualization of topics estimated using Latent Dirichlet Allocation that is built using a combination of R and D3. Our visualization provides a global view of the topics (and how they differ from each other), while at the same time allowing for a deep inspection of the terms most highly associated with each individual topic. First, we propose a novel method for choosing which terms to present to a user to aid in the task of topic interpretation, in which we define the relevance of a term to a topic. Second, we present results from a user study that suggest that ranking terms purely by their probability under a topic is suboptimal for topic interpretation. Last, we describe LDAvis, our visualization system that allows users to flexibly explore topic-term relationships using relevance to better understand a fitted LDA model.},
   author = {Carson Sievert and Kenneth E Shirley},
   doi = {10.3115/V1/W14-3110},
   month = {6},
   pages = {63-70},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {LDAvis: A method for visualizing and interpreting topics},
   url = {https://aclanthology.org/W14-3110},
   year = {2014},
}
@article{Ahmed2021,
   abstract = {In the recent past, the world in general and Pakistan in particular faced a drastic fuel price change, affecting the economic productivity of the country. This has drawn the attention of empirical researchers to analyze the abrupt change in fuel prices. This study takes a lead and investigates for the first time, in the literature related to Pakistan, the presence of multiple fuel price bubbles, with the purpose of knowing if the price driver is due to demand or it is exuberant consumer behavior that prevails and contributes to a sudden boom in fuel price series. The empirical analysis is performed through a recently proposed state-of-the-art generalized sup ADF (GSADF) approach on six commonly used fuel price series, namely, LDO (light diesel oil), HSD (high-speed diesel), petrol, natural gas, kerosene, and MS (motor spirit). The bubble analysis for each of the six fuel price series is based on monthly data from July 2005 to August 2020. The findings provide evidence of the existence of multiple bubbles in all series considered. Specifically, four bubbles are detected in each of the kerosene and natural gas price series, whereas three bubbles are noted in each of the HSD, LDO, petrol and MS price series. The maximum duration of occurrence of bubbles is of 12 months for kerosene. The date-stamping of the bubbles shows that the financial crisis of 2008 contributed to the emergence of bubbles that pushed oil prices upward and caused a depreciation in the national currency.},
   author = {Mumtaz Ahmed and Muhammad Irfan and Abdelrhman Meero and Maryam Tariq and Ubaldo Comite and Abdul Aziz Abdul Rahman and Muhammad Safdar Sial and Stefan B. Gunnlaugsson},
   doi = {10.3390/PR10010065},
   issn = {2227-9717},
   issue = {1},
   journal = {Processes 2022, Vol. 10, Page 65},
   keywords = {GSADF,Pakistan,bubble length,petroleum products,price bubbles},
   month = {12},
   pages = {65},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Bubble Identification in the Emerging Economy Fuel Price Series: Evidence from Generalized Sup Augmented Dickey&ndash;Fuller Test},
   volume = {10},
   url = {https://www.mdpi.com/2227-9717/10/1/65/htm https://www.mdpi.com/2227-9717/10/1/65},
   year = {2021},
}
@article{Escobari2016,
   abstract = {We test for the existence of single and multiple bubble periods in four Real Estate Investment Trust (REIT) indices using the Supremum Augmented Dickey-Fuller (SADF) and the Generalized SADF. These methods allow us to estimate the beginning and the end of bubble periods. Our results provide statistically significant evidence of speculative bubbles in the REIT index and its three components: Equity, Mortgage and Hybrid REITs. These results may be valuable for real estate financial managers and for investors in REITs.},
   author = {Diego Escobari and Mohammad Jafarinejad},
   doi = {10.1016/J.QREF.2015.10.003},
   issn = {1062-9769},
   journal = {The Quarterly Review of Economics and Finance},
   keywords = {Generalized sup ADF,REITs,Real estate,Speculative bubbles},
   month = {5},
   pages = {224-230},
   publisher = {North-Holland},
   title = {Date stamping bubbles in Real Estate Investment Trusts},
   volume = {60},
   year = {2016},
}
@article{Bouri2019,
   abstract = {Most of the limited evidence on the exponential price spikes (i.e. price explosivity) in the cryptocurrency market mainly considers the case of Bitcoin, although other cryptocurrencies have gradually eroded Bitcoin's dominance. Importantly, none has been documented as to whether explosivity periods in cryptocurrencies are contemporaneously related. Accordingly, we date-stamp price explosivity in leading cryptocurrencies and reveal that all cryptocurrencies investigated herein were characterised by multiple explosivity. Then, we determine whether explosivity in one cryptocurrency can lead to explosivity in other cryptocurrencies. Results show evidence of a multidirectional co-explosivity behaviour that is not necessarily from bigger to smaller and younger markets.},
   author = {Elie Bouri and Syed Jawad Hussain Shahzad and David Roubaud},
   doi = {10.1016/J.FRL.2018.07.005},
   issn = {1544-6123},
   journal = {Finance Research Letters},
   keywords = {Bitcoin,Bubble,Co-explosivity,Cryptocurrency market},
   month = {6},
   pages = {178-183},
   publisher = {Elsevier},
   title = {Co-explosivity in the cryptocurrency market},
   volume = {29},
   year = {2019},
}
@article{Kyriazis2020,
   abstract = {This paper surveys the academic literature concerning the formation of pricing bubbles in digital currency markets. Studies indicate that several bubble phases have taken place in Bitcoin prices, mostly during the years 2013 and 2017. Other digital currencies of primary importance, such as Ethereum and Litecoin, also exhibit several bubble phases. The Augmented Dickey Fuller (ADF) as well as the Log-Periodic Power Law (LPPL) methodology are the most frequently employed techniques for bubble detection and measurement. Based on much academic research, Bitcoin appears to have been in a bubble-phase since June 2015, while Ethereum, NEM, Stellar, Ripple, Litecoin and Dash have been denoted as possessing bubble-like characteristics since September 2015. However, this latter group possess little academic evidence supporting the presence of bubbles since early 2018. An overall perspective is provided based on a robust bibliography based on large deviations of market quotes from fundamental values that can serve as a guide to policymakers, academics and investors.},
   author = {Nikolaos Kyriazis and Stephanos Papadamou and Shaen Corbet},
   doi = {10.1016/J.RIBAF.2020.101254},
   issn = {0275-5319},
   journal = {Research in International Business and Finance},
   keywords = {Bitcoin,Cryptocurrencies,Pricing bubbles,Systematic review},
   month = {12},
   pages = {101254},
   publisher = {Elsevier},
   title = {A systematic review of the bubble dynamics of cryptocurrency prices},
   volume = {54},
   year = {2020},
}
@article{Corbet2018,
   abstract = {We examine the existence and dates of pricing bubbles in Bitcoin and Ethereum, two popular cryptocurrencies using the (Phillips et al., 2011) methodology. In contrast to previous papers, we examine the fundamental drivers of the price. Having derived ratios that are economically and computationally sensible, we use these variables to detect and datestamp bubbles. Our conclusion is that there are periods of clear bubble behaviour, with Bitcoin now almost certainly in a bubble phase.},
   author = {Shaen Corbet and Brian Lucey and Larisa Yarovaya},
   doi = {10.1016/J.FRL.2017.12.006},
   issn = {1544-6123},
   journal = {Finance Research Letters},
   keywords = {Bitcoin,Bubbles,Cryptocurrencies,Digital assets,Ethereum},
   month = {9},
   pages = {81-88},
   publisher = {Elsevier},
   title = {Datestamping the Bitcoin and Ethereum bubbles},
   volume = {26},
   year = {2018},
}
@article{Grossmann1988,
   author = {Herschel Grossmann and Behzad Diba},
   issue = {3},
   journal = {The American Economic Review},
   month = {6},
   pages = {520-530},
   title = {Explosive Rational Bubbles in Stock Prices?},
   volume = {78},
   url = {https://www.jstor.org/stable/1809149#metadata_info_tab_contents},
   year = {1988},
}
@article{Cheung2015,
   abstract = {The creation of bitcoin heralded the arrival of digital or crypto-currency and has been regarded as a phenomenon. Since its introduction, it has experienced a meteoric rise in price and rapid growt...},
   author = {Adrian (Wai Kong) Cheung and Eduardo Roca and Jen Je Su},
   doi = {10.1080/00036846.2015.1005827},
   issn = {14664283},
   issue = {23},
   journal = {Applied Economics},
   keywords = {C10,G10,G12,bitcoin,bubbles,crypto-currency},
   month = {5},
   pages = {2348-2358},
   publisher = {Routledge},
   title = {Crypto-currency bubbles: an application of the Phillips–Shi–Yu (2013) methodology on Mt. Gox bitcoin prices},
   volume = {47},
   url = {https://www.tandfonline.com/doi/abs/10.1080/00036846.2015.1005827},
   year = {2015},
}
@article{Caspi2018,
   abstract = {This paper sets out to date-stamp periods of historic oil price explosivity using the Generalized sup ADF (GSADF) test procedure developed by Phillips, Shi, and Yu (2013). The date-stamping procedure used in this paper is effective at identifying periodically collapsing bubbles; a feature found lacking with previous bubble detection methods. We set out to identify periods of oil price explosivity relative to the general price level and oil inventory supplies in the US since 1876 and 1920, respectively. The recursive identification algorithms used in this study identify multiple periods of price explosivity, and as such provides future researchers with a reference for studying the macroeconomic impact of historical periods of significant oil price build-ups.},
   author = {Itamar Caspi and Nico Katzke and Rangan Gupta},
   doi = {10.1016/J.ENECO.2015.03.029},
   issn = {0140-9883},
   journal = {Energy Economics},
   keywords = {Commodity price bubbles,Date-stamping strategy,Explosivity,Flexible window,GSADF test,Oil-prices,Periodically collapsing bubbles},
   month = {2},
   pages = {582-587},
   publisher = {North-Holland},
   title = {Date stamping historical periods of oil price explosivity: 1876–2014},
   volume = {70},
   year = {2018},
}
@article{Fisher2019,
   author = {Katya Fisher},
   journal = {Cardozo Arts & Entertainment Law Journal},
   title = {Once upon a Time in NFT: Blockchain, Copyright, and the Right of First Sale Doctrine},
   volume = {37},
   url = {https://heinonline.org/HOL/Page?handle=hein.journals/caelj37&id=665&div=&collection=},
   year = {2019},
}
@article{Diba1987,
   abstract = {A rational bubble would involve a self-confirming belief that an asset price depends on information that includes variables or parameters that are not part of market fundamentals. The existing literature shows that, if market fundamentals are economically interesting, i.e., forward looking, any rational bubbles would be either explosive or implosive. Further arguments based on the existing literature show that utility maximizing behavior implies finite bounds on asset prices and, accordingly, precludes both explosive and implosive rational price expectations, except for the possible case of an implosion in the value of fiat money. These arguments rule out both positive and negative rational bubbles, except for the poissibility of rational inflationary bubbles.This paper extends the theoretical analysis of rational bubbles in two ways. First, it shows that, although a supply response of the current asset stock to the current asset price dampens fluctuations in market fundamentals, such a response would cause a rational bubble to explode or to implode even faster.Thus, the explosiveness or implosiveness of rational bubbles isnot an artifact of assuming that the asset stock evolves autonomously. Second, and more importantly, the present analysis considers the inception of rational bubbles and shows that, for anegative rational bubble -- such as a rational inflationary bubble -- to get started, a positive rational bubble also would have to have positive probability. Specifically, the expected initial absolute value of a potential negative rational bubble cannot exceed the expected, initial value of a potential positive rational bubble.This result dramatically expands the theoretical basis for precluding rational bubbles. Specifically, because utility maximization directly rules out rational deflationary bubbles, the inception of a rational inflationary bubbles is also precluded.},
   author = {Behzad T. Diba and Herschel I. Grossman},
   doi = {10.2307/1884225},
   issn = {0033-5533},
   issue = {3},
   journal = {The Quarterly Journal of Economics},
   month = {8},
   pages = {697-700},
   publisher = {Oxford Academic},
   title = {On the Inception of Rational Bubbles},
   volume = {102},
   url = {https://academic.oup.com/qje/article/102/3/697/1888040},
   year = {1987},
}
@article{Ewans1991,
   author = {George W. Ewans},
   issue = {4},
   journal = {The American Economic Review},
   month = {9},
   pages = {922-930},
   title = {Pitfalls in Testing for Explosive Bubbles in Asset Prices},
   volume = {81},
   url = {https://www.jstor.org/stable/2006651#metadata_info_tab_contents},
   year = {1991},
}
@article{Bao2022,
   abstract = {The popularity of the Non-Fungible Token (NFT) has risen rapidly since 2020, becoming one of the most popular applications in the Fintech field. However, there has so far been no attempt to perform a systematic review in this new area. Considering the items of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), this paper conducts a systematic review of the research work on NFT, published in journals indexed at the Web of Science and ScienceDirect until April 2022. The results reveal that there are 13 published articles in the targeted journals and they are mainly focused on the asset pricing area. The research gaps identified in the literature also can be the opportunity for future study. Thus, we lay down the research agenda for the future in several important but unanswered fields related to asset pricing, tokenomics, and risk and regulation.},
   author = {Hong Bao and David Roubaud},
   doi = {10.3390/JRFM15050215},
   issn = {1911-8074},
   issue = {5},
   journal = {Journal of Risk and Financial Management 2022, Vol. 15, Page 215},
   keywords = {fungible token,non,research agenda,systematic review},
   month = {5},
   pages = {215},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Non-Fungible Token: A Systematic Review and Research Agenda},
   volume = {15},
   url = {https://www.mdpi.com/1911-8074/15/5/215/htm https://www.mdpi.com/1911-8074/15/5/215},
   year = {2022},
}
@article{Wilson2021,
   abstract = {Non-fungible tokens (NFTs) are a highly nascent and emerging phenomenon revolutionizing how digital assets are traded. NFTs embody immutable rights to unique digital assets such as digital art and collectibles and are represented as digital tokens that can be traded across marketplaces utilizing blockchain technologies. NFTs engender new ways to organize, consume, move, program, and store digital information and have experienced a rapid rise in various adaptations across art, sports, broadcasting, content creation, and tech-crypto businesses. In this article, we define NFTs and look at how they fit with blockchain and cryptocurrencies, how they are used by various industries, and the opportunities and risks they present. Our key contribution is a conceptual map of an initial NFT ecosystem. In doing so, we provide relational mapping between and among key stakeholders: content creators, core and related technical and business intermediaries, consumers, investors, and speculators. We also highlight implications for managers and tie them to conceptual exploration and exploitation frameworks.},
   author = {Kathleen Bridget Wilson and Adam Karg and Hadi Ghaderi},
   doi = {10.1016/J.BUSHOR.2021.10.007},
   issn = {0007-6813},
   journal = {Business Horizons},
   keywords = {Blockchain,Business ecosystem,Digital innovation,NFT,Non-fungible tokens},
   month = {10},
   publisher = {Elsevier},
   title = {Prospecting non-fungible tokens in the digital economy: Stakeholders and ecosystem, risk and opportunity},
   year = {2021},
}
@web_page{Kapadia2019,
   author = {Shashank Kapadia},
   month = {4},
   title = {Topic Modeling in Python: Latent Dirichlet Allocation (LDA) | by Shashank Kapadia | Towards Data Science},
   url = {https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0},
   year = {2019},
}
@article{Panichella2021,
   abstract = {Context:Latent Dirichlet Allocation (LDA) has been successfully used in the literature to extract topics from software documents and support developers in various software engineering tasks. While LDA has been mostly used with default settings, previous studies showed that default hyperparameter values generate sub-optimal topics from software documents. Objective: Recent studies applied meta-heuristic search (mostly evolutionary algorithms) to configure LDA in an unsupervised and automated fashion. However, previous work advocated for different meta-heuristics and surrogate metrics to optimize. The objective of this paper is to shed light on the influence of these two factors when tuning LDA for SE tasks. Method:We empirically evaluated and compared seven state-of-the-art meta-heuristics and three alternative surrogate metrics (i.e., fitness functions) to solve the problem of identifying duplicate bug reports with LDA. The benchmark consists of ten real-world and open-source projects from the Bench4BL dataset. Results:Our results indicate that (1) meta-heuristics are mostly comparable to one another (except for random search and CMA-ES), and (2) the choice of the surrogate metric impacts the quality of the generated topics and the tuning overhead. Furthermore, calibrating LDA helps identify twice as many duplicates than untuned LDA when inspecting the top five past similar reports. Conclusion:No meta-heuristic and/or fitness function outperforms all the others, as advocated in prior studies. However, we can make recommendations for some combinations of meta-heuristics and fitness functions over others for practical use. Future work should focus on improving the surrogate metrics used to calibrate/tune LDA in an unsupervised fashion.},
   author = {Annibale Panichella},
   doi = {10.1016/J.INFSOF.2020.106411},
   issn = {0950-5849},
   journal = {Information and Software Technology},
   keywords = {Duplicate bug report,Hyperparameter optimization,Latent dirichlet allocation,Metaheuristic search,Search-based software engineering,Topic modeling},
   month = {2},
   pages = {106411},
   publisher = {Elsevier},
   title = {A Systematic Comparison of search-Based approaches for LDA hyperparameter tuning},
   volume = {130},
   year = {2021},
}
@article{Agrawal2018,
   abstract = {Context: Topic modeling finds human-readable structures in unstructured textual data. A widely used topic modeling technique is Latent Dirichlet allocation. When running on different datasets, LDA suffers from “order effects”, i.e., different topics are generated if the order of training data is shuffled. Such order effects introduce a systematic error for any study. This error can relate to misleading results; specifically, inaccurate topic descriptions and a reduction in the efficacy of text mining classification results. Objective: To provide a method in which distributions generated by LDA are more stable and can be used for further analysis. Method: We use LDADE, a search-based software engineering tool which uses Differential Evolution (DE) to tune the LDA's parameters. LDADE is evaluated on data from a programmer information exchange site (Stackoverflow), title and abstract text of thousands of Software Engineering (SE) papers, and software defect reports from NASA. Results were collected across different implementations of LDA (Python+Scikit-Learn, Scala+Spark) across Linux platform and for different kinds of LDAs (VEM, Gibbs sampling). Results were scored via topic stability and text mining classification accuracy. Results: In all treatments: (i) standard LDA exhibits very large topic instability; (ii) LDADE's tunings dramatically reduce cluster instability; (iii) LDADE also leads to improved performances for supervised as well as unsupervised learning. Conclusion: Due to topic instability, using standard LDA with its “off-the-shelf” settings should now be depreciated. Also, in future, we should require SE papers that use LDA to test and (if needed) mitigate LDA topic instability. Finally, LDADE is a candidate technology for effectively and efficiently reducing that instability.},
   author = {Amritanshu Agrawal and Wei Fu and Tim Menzies},
   doi = {10.1016/J.INFSOF.2018.02.005},
   issn = {0950-5849},
   journal = {Information and Software Technology},
   keywords = {Differential evolution,LDA,Stability,Topic modeling,Tuning},
   month = {6},
   pages = {74-88},
   publisher = {Elsevier},
   title = {What is wrong with topic modeling? And how to fix it using search-based software engineering},
   volume = {98},
   year = {2018},
}
@article{Panichella2013,
   abstract = {Information Retrieval (IR) methods, and in particular topic models, have recently been used to support essential software engineering (SE) tasks, by enabling software textual retrieval and analysis. In all these approaches, topic models have been used on software artifacts in a similar manner as they were used on natural language documents (e.g., using the same settings and parameters) because the underlying assumption was that source code and natural language documents are similar. However, applying topic models on software data using the same settings as for natural language text did not always produce the expected results. Recent research investigated this assumption and showed that source code is much more repetitive and predictable as compared to the natural language text. Our paper builds on this new fundamental finding and proposes a novel solution to adapt, configure and effectively use a topic modeling technique, namely Latent Dirichlet Allocation (LDA), to achieve better (acceptable) performance across various SE tasks. Our paper introduces a novel solution called LDA-GA, which uses Genetic Algorithms (GA) to determine a near-optimal configuration for LDA in the context of three different SE tasks: (1) traceability link recovery, (2) feature location, and (3) software artifact labeling. The results of our empirical studies demonstrate that LDA-GA is able to identify robust LDA configurations, which lead to a higher accuracy on all the datasets for these SE tasks as compared to previously published results, heuristics, and the results of a combinatorial search. © 2013 IEEE.},
   author = {Annibale Panichella and Bogdan Dit and Rocco Oliveto and Massimilano Di Penta and Denys Poshynanyk and Andrea De Lucia},
   doi = {10.1109/ICSE.2013.6606598},
   isbn = {9781467330763},
   issn = {02705257},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Genetic Algoritms,Latent Dirichlet Allocation,Textual Analysis in Software Engineering},
   pages = {522-531},
   title = {How to effectively use topic models for software engineering tasks? An approach based on Genetic Algorithms},
   year = {2013},
}
@article{Bischof2012,
   abstract = {Recent work in text analysis commonly describes topics in terms of their most frequent words, but the exclusivity of words to topics is equally important for communicating content. We introduce Hierarchical Poisson Convolution (HPC), a model which infers regularized estimates of the differential use of words across topics as well as their frequency within topics. HPC uses known hierarchical structure on human-labeled topics to make focused comparisons of differential usage within each branch of the hierarchy of labels. We then infer a summary for each topic in terms of words that are both frequent and exclusive. We develop a parallelized Hamil-tonian Monte Carlo sampler that allows for fast and scalable computation.},
   author = {Jonathan M Bischof and Edoardo M Airoldi},
   journal = {Proceedings of the 29th International Conference on Machine Learning (ICML-12).},
   pages = {201-208},
   title = {Summarizing topical content with word frequency and exclusivity},
   year = {2012},
}
@article{Taddy2012,
   abstract = {This article describes posterior maximization for topic models, identifying computational and conceptual gains from inference under a non-standard parametrization. We then show that fitted parameters can be used as the basis for a novel approach to marginal likelihood estimation, via block-diagonal approximation to the information matrix, that facilitates choosing the number of latent topics. This likelihood-based model selection is complemented with a goodness-of-fit analysis built around estimated residual dispersion. Examples are provided to illustrate model selection as well as to compare our estimation against standard alternative techniques.},
   author = {Matthew A Taddy},
   title = {On Estimation and Selection for Topic Models},
   year = {2012},
}
@article{Nadini2021,
   abstract = {Non Fungible Tokens (NFTs) are digital assets that represent objects like art, collectible, and in-game items. They are traded online, often with cryptocurrency, and are generally encoded within smart contracts on a blockchain. Public attention towards NFTs has exploded in 2021, when their market has experienced record sales, but little is known about the overall structure and evolution of its market. Here, we analyse data concerning 6.1 million trades of 4.7 million NFTs between June 23, 2017 and April 27, 2021, obtained primarily from Ethereum and WAX blockchains. First, we characterize statistical properties of the market. Second, we build the network of interactions, show that traders typically specialize on NFTs associated with similar objects and form tight clusters with other traders that exchange the same kind of objects. Third, we cluster objects associated to NFTs according to their visual features and show that collections contain visually homogeneous objects. Finally, we investigate the predictability of NFT sales using simple machine learning algorithms and find that sale history and, secondarily, visual features are good predictors for price. We anticipate that these findings will stimulate further research on NFT production, adoption, and trading in different contexts.},
   author = {Matthieu Nadini and Laura Alessandretti and Flavio Di Giacinto and Mauro Martino and Luca Maria Aiello and Andrea Baronchelli},
   doi = {10.1038/s41598-021-00053-8},
   isbn = {0123456789},
   issn = {2045-2322},
   issue = {1},
   journal = {Scientific Reports 2021 11:1},
   keywords = {Information theory and computation,Statistical physics,thermodynamics and nonlinear dynamics},
   month = {10},
   pages = {1-11},
   pmid = {34686678},
   publisher = {Nature Publishing Group},
   title = {Mapping the NFT revolution: market trends, trade networks, and visual features},
   volume = {11},
   url = {https://www.nature.com/articles/s41598-021-00053-8},
   year = {2021},
}
@article{Das2022,
   abstract = {Non-Fungible Tokens (NFTs) have emerged as a way to collect digital art as well as an investment vehicle. Despite having been popularized only recently, NFT markets have witnessed several high-profile (and high-value) asset sales and a tremendous growth in trading volumes over the last year. Unfortunately, these marketplaces have not yet received much security scrutiny. Instead, most academic research has focused on attacks against decentralized finance (DeFi) protocols and automated techniques to detect smart contract vulnerabilities. To the best of our knowledge, we are the first to study the market dynamics and security issues of the multi-billion dollar NFT ecosystem. In this paper, we first present a systematic overview of how the NFT ecosystem works, and we identify three major actors: marketplaces , external entities, and users. We then perform an in-depth analysis of the top 8 marketplaces (ranked by transaction volume) to discover potential issues, many of which can lead to substantial financial losses. We also collected a large amount of asset and event data pertaining to the NFTs being traded in the examined marketplaces. We automatically analyze this data to understand how the entities external to the blockchain are able to interfere with NFT markets, leading to serious consequences, and quantify the malicious trading behaviors carried out by users under the cloak of anonymity. CCS CONCEPTS • Security and privacy → Web application security.},
   author = {Dipanjan Das and Priyanka Bose and Nicola Ruaro and Christopher Kruegel and Giovanni Vigna and Gio-Vanni Vigna},
   keywords = {Blockchain,Decentralization,Non-fungible token},
   title = {Understanding Security Issues in the NFT Ecosystem},
   url = {https://arxiv.org/abs/2111.08893},
   year = {2022},
}
@web_page{Artcoffee,
   title = {Art & Coffee - Metaverse gallery},
   url = {https://www.artcoffee.info/},
   year = {2021},
}
@article{Lee2021,
   abstract = {Since the popularisation of the Internet in the 1990s, the cyberspace has
kept evolving. We have created various computer-mediated virtual environments
including social networks, video conferencing, virtual 3D worlds (e.g., VR
Chat), augmented reality applications (e.g., Pokemon Go), and Non-Fungible
Token Games (e.g., Upland). Such virtual environments, albeit non-perpetual and
unconnected, have bought us various degrees of digital transformation. The term
`metaverse' has been coined to further facilitate the digital transformation in
every aspect of our physical lives. At the core of the metaverse stands the
vision of an immersive Internet as a gigantic, unified, persistent, and shared
realm. While the metaverse may seem futuristic, catalysed by emerging
technologies such as Extended Reality, 5G, and Artificial Intelligence, the
digital `big bang' of our cyberspace is not far away. This survey paper
presents the first effort to offer a comprehensive framework that examines the
latest metaverse development under the dimensions of state-of-the-art
technologies and metaverse ecosystems, and illustrates the possibility of the
digital `big bang'. First, technologies are the enablers that drive the
transition from the current Internet to the metaverse. We thus examine eight
enabling technologies rigorously - Extended Reality, User Interactivity
(Human-Computer Interaction), Artificial Intelligence, Blockchain, Computer
Vision, IoT and Robotics, Edge and Cloud computing, and Future Mobile Networks.
In terms of applications, the metaverse ecosystem allows human users to live
and play within a self-sustaining, persistent, and shared realm. Therefore, we
discuss six user-centric factors -- Avatar, Content Creation, Virtual Economy,
Social Acceptability, Security and Privacy, and Trust and Accountability.
Finally, we propose a concrete research agenda for the development of the
metaverse.},
   author = {Lik-Hang Lee and Tristan Braud and Pengyuan Zhou and Lin Wang and Dianlei Xu and Zijun Lin and Abhishek Kumar and Carlos Bermejo and Pan Hui},
   doi = {10.48550/arxiv.2110.05352},
   month = {10},
   title = {All One Needs to Know about Metaverse: A Complete Survey on Technological Singularity, Virtual Ecosystem, and Research Agenda},
   url = {https://arxiv.org/abs/2110.05352v3},
   year = {2021},
}
@web_page{ArtBlocks,
   author = {artblocks},
   title = {art blocks},
   url = {https://www.artblocks.io/learn},
   year = {2021},
}
@web_page{Thomas2021,
   author = {Langston Thomas},
   month = {9},
   title = {Punks Comic: The Ultimate Guide},
   url = {https://nftnow.com/guides/punks-comic-guide/},
   year = {2021},
}
@web_page{Cryptopedia2022,
   author = {Cryptopedia},
   month = {2},
   title = {SuperRare: An Exclusive, Curated NFT Platform},
   url = {https://www.gemini.com/cryptopedia/superrare-nft-marketplace-superrare-crypto-art-market},
   year = {2022},
}
@web_page{Loot2021,
   author = {Loot},
   title = {Loot},
   url = {https://www.lootproject.com/faq},
   year = {2021},
}
@web_page{Paredes2022,
   author = {JC Paredes},
   month = {1},
   title = {Wolf Game (\$WOOL), NFT Blockchain Game Explained},
   url = {https://www.spieltimes.com/news/wolf-game-wool-nft-blockchain-game-explained/},
   year = {2022},
}
@web_page{Otherside2022,
   author = {Otherside},
   title = {The Otherside Litepaper},
   url = {https://otherside.xyz/litepaper},
   year = {2022},
}
@web_page{Gottsegen2022,
   author = {Will Gottsegen and Eli Tan},
   month = {5},
   title = {BAYC Team Raises \$285M With Otherside NFTs, Clogs Ethereum},
   url = {https://markets.businessinsider.com/news/currencies/bayc-team-raises-285m-with-otherside-nfts-clogs-ethereum-1031405129},
   year = {2022},
}
@web_page{Sandbox2020,
   author = {The Sandbox},
   month = {6},
   title = {What Is The Sandbox?},
   url = {https://medium.com/sandbox-game/what-is-the-sandbox-850de68d893e},
   year = {2020},
}
@web_page{larvalabs2017,
   author = {larvalabs},
   title = {CryptoPunks},
   url = {https://www.larvalabs.com/cryptopunks},
   year = {2017},
}
@web_page{BAYC2021,
   author = {BAYC},
   title = {BAYC},
   url = {https://boredapeyachtclub.com/#/home},
   year = {2021},
}
@web_page{Meebits2021,
   author = {Meebits},
   title = {The Meebits},
   url = {https://meebits.app/},
   year = {2021},
}
@web_page{Murphy2022,
   author = {Casey Murphy},
   month = {3},
   title = {What Is Axie Infinity?},
   url = {https://www.investopedia.com/what-is-axie-infinity-5220657},
   year = {2022},
}
@web_page{Kaur2021,
   author = {Harpreet Kaur},
   month = {12},
   title = {What is Neo Tokyo Identities NFT Collection? Everything you need to Know},
   url = {https://cryptobullsclub.com/neo-tokyo-identities-nft-collection/},
   year = {2021},
}
@web_page{ENS2021,
   author = {ENS Documentation},
   title = {Introduction},
   url = {https://docs.ens.domains/},
   year = {2021},
}
@web_page{Flooz2022,
   author = {Flooz},
   title = {Flooz},
   url = {https://docs.flooz.trade/},
   year = {2022},
}
@article{Coslor2019,
   abstract = {This research examines gatekeepers’ categorization work to assess and sort audience members. Using a multi-sited ethnography and interpretivist qualitative lens, we explore how high-value art galle...},
   author = {Erica Coslor and Brett Crawford and Andrew Leyshon},
   doi = {10.1177/0170840619883371},
   issn = {17413044},
   issue = {7},
   journal = {Organization Studies},
   keywords = {artistic consecration,buyer categories,categories,duty of care assessments,gatekeeping,market intermediaries,strategic placement,value construction},
   month = {12},
   pages = {945-967},
   publisher = {SAGE PublicationsSage UK: London, England},
   title = {Collectors, Investors and Speculators: Gatekeeper use of audience categories in the art market},
   volume = {41},
   url = {https://journals.sagepub.com/doi/full/10.1177/0170840619883371?casa_token=QXjoWlL9EtUAAAAA%3AdPrxZzXH7-HsvFUkHl0TFcWaWakpNYJEFrCbcOxWb50TgepjL4D0WO8DBP9NtW0UZR5jL8-NIUousw},
   year = {2019},
}
@article{Mazur2021,
   abstract = {This study examines the risk and return characteristics of the NFT-based startups listed on the cryptocurrency exchange. Our investigation is motivated by the recent surge in the NFT activity on the part of creators, investors, and traders. We begin by proposing novel classification of the existing NFTs that range from NFT blockchains through NFT metaverse to NFT DeFi. Next, we establish that NFTs: 1) earn 130\% on the first-listing-day; 2) yield an average investment multiple of 40 (roughly 4,000\%) over long-term, which is four times higher than bitcoin during the same period; 3) deliver positive and significant alpha and exhibit above-average beta. We also show that the NFT segment of the cryptocurrency market leads market recovery following the mid-2021 crash and generate a return of close to 350\%. In the final analysis of the paper, we find that NFT infrastructure integrated within the existing blockchains increase market valuations of these networks. 1This},
   author = {Mieszko Mazur},
   doi = {10.2139/SSRN.3953535},
   journal = {SSRN Electronic Journal},
   keywords = {Blockchain,Cryptocurrency,DeFi,Decentralised Finance,Metaverse,Mieszko Mazur,NFT,Non-Fungible Token,Non-Fungible Tokens (NFT). The Analysis of Risk and Return,Return,Risk,SSRN,Volatility},
   month = {10},
   publisher = {Elsevier BV},
   title = {Non-Fungible Tokens (NFT). The Analysis of Risk and Return},
   url = {https://papers.ssrn.com/abstract=3953535},
   year = {2021},
}
@article{Mamarbachi2011,
   abstract = {The paper constitutes a discussion of the trend around the rise of art as an alternative investment. With financial markets in turmoil, art as an alternative asset class is being incorporated into portfolios in the interest of diversification. Art's low correlation with the equities market and desirable risk and reward ratio, as price appreciation defies all logic, makes it an attractive investment.     The volatility, irrationality and illiquidity of the art market make it hard to compare to more conventional investments. The paper will look at how investors are treating art as an asset class and how art compares to more traditional assets such as equities and bonds.},
   author = {Raya Mamarbachi and Marc Day and Giampiero Favato},
   doi = {10.2139/SSRN.1112630},
   journal = {SSRN Electronic Journal},
   keywords = {Art as an Alternative Investment Asset,Giampiero Favato,Marc Day,Raya Mamarbachi,SSRN,art,class,economics,fund,investment,returns,risk,volatility},
   month = {12},
   publisher = {Elsevier BV},
   title = {Art as an Alternative Investment Asset},
   url = {https://papers.ssrn.com/abstract=1112630},
   year = {2011},
}
@web_page{Kaczynski2021,
   author = {Steve Kaczynski and Scott Duke Kominers},
   journal = {Harvard Business Review},
   month = {11},
   title = {How NFTs Create Value},
   url = {https://hbr.org/2021/11/how-nfts-create-value},
   year = {2021},
}
@article{Park2022,
   abstract = {Nonfungible tokens (NFTs) have recently drawn considerable attention, highlighted by a digital art piece that sold for '69M USD in early 2021. Though they have only just started receiving coverage by traditional media outlets and interest from casual observers, the foundations of NFT technology date back to advances in computer science in the late 1970s. In this article, we examine the emergence of NFTs, from their technical origins, the introduction of blockchain technologies and the first token-based collectibles that led to modern day NFT products. We categorize the current use cases for NFTs, introduce their potential future applications, and highlight the challenges managers face in incorporating them into their existing workflows. By presenting our NFT adoption framework, we offer managers strategies for evaluating the risks and benefits of NFTs.},
   author = {Andrew Park and Jan Kietzmann and Leyland Pitt and Amir Dabirian},
   doi = {10.1109/MITP.2021.3136055},
   issn = {1941045X},
   issue = {1},
   journal = {IT Professional},
   pages = {9-14},
   publisher = {IEEE Computer Society},
   title = {The Evolution of Nonfungible Tokens: Complexity and Novelty of NFT Use-Cases},
   volume = {24},
   year = {2022},
}
@article{Lawton2017,
   abstract = {Today, mobile technology has become a ubiquitous influence on the way we live. In 1996, however, mobile devices were clumsy and remained distinctly outside of the consumer’s social fabric. Bandai Inc’s introduction of the Tamagotchi, a toy that could be taken anywhere, and portrayed a pixelated alien in need of constant nurturing, represented a significant shift in the role of mobile technology in daily life. Through its cuteness, the Tamagotchi convinced consumers to willingly dedicate their time, attention, and emotions to the virtual pet. This paper will explore how the Tamagotchi played a role in influencing how individuals viewed the developing mobile technology market, and how it prepared us for the constant presence of technology that we are so familiar with today.},
   author = {Laura Lawton},
   issn = {2561-7397},
   issue = {2},
   journal = {The iJournal: Student Journal of the Faculty of Information},
   keywords = {Tamagotchi,digital pets,mobile technology},
   month = {3},
   title = {Taken by the Tamagotchi: How a Toy Changed the Perspective on Mobile Technology},
   volume = {2},
   url = {https://theijournal.ca/index.php/ijournal/article/view/28127},
   year = {2017},
}
@article{Boons2013,
   abstract = {Sustainable development requires radical and systemic innovations. Such innovations can be more effectively created and studied when building on the concept of business models. This concept provides firms with a holistic framework to envision and implement sustainable innovations. For researchers, the concept provides an analytical tool that allows them to assess the interplay between the different aspects that firms combine to create ecological, economic, and social value. In addition, the business model concept provides a link between the individual firm and the larger production and consumption system in which it operates. This paper provides an introduction to the special issue, which emerged from selected papers presented at the ERSCP-EMSU 2010 Conference held in Delft, The Netherlands. Papers in the special issue cover a broad range, from a conceptual discussion resulting in a research agenda, the assessment of diffusion of specific business models such as Product-Service Systems, the introduction of new management tools for business transition management, to case studies on how specific business models evolved in specific communities. Together, these papers provide insight into the promise of the business model concept for understanding and advancing sustainable innovation. © 2013 Published by Elsevier Ltd.},
   author = {Frank Boons and Carlos Montalvo and Jaco Quist and Marcus Wagner},
   doi = {10.1016/J.JCLEPRO.2012.08.013},
   issn = {0959-6526},
   journal = {Journal of Cleaner Production},
   keywords = {Competitiveness,Economic performance,Innovation diffusion,Sustainable business models,Sustainable innovation},
   month = {4},
   pages = {1-8},
   publisher = {Elsevier},
   title = {Sustainable innovation, business models and economic performance: an overview},
   volume = {45},
   year = {2013},
}
@article{Cillo2019,
   abstract = {In order to adhere to the concept of sustainable development, firms are increasingly expected to develop innovations that reconcile economic, environmental, and social goals (i.e., sustainable innovations). However, achieving this goal is not straightforward, and although several studies have attempted to improve our understanding of sustainable innovation, a systematization of extant findings is lacking. Therefore, this paper conducts a literature review with the objective of organizing previous research regarding sustainable innovation. A systematic approach is adopted, identifying 69 relevant articles. These articles are organized according to three key perspectives: internal managerial, external relational, and performance evaluation. The results demonstrate that the first perspective, incorporating diverse managerial aspects, is the most considered, whereas the second and third perspectives remain underdeveloped. The paper concludes with suggestions for future research.},
   author = {Valentina Cillo and Antonio Messeni Petruzzelli and Lorenzo Ardito and Manlio Del Giudice},
   doi = {10.1002/CSR.1783},
   issn = {1535-3966},
   issue = {5},
   journal = {Corporate Social Responsibility and Environmental Management},
   keywords = {sustainable development,sustainable innovation,systematic literature review},
   month = {9},
   pages = {1012-1025},
   publisher = {John Wiley & Sons, Ltd},
   title = {Understanding sustainable innovation: A systematic literature review},
   volume = {26},
   url = {https://onlinelibrary.wiley.com/doi/full/10.1002/csr.1783 https://onlinelibrary.wiley.com/doi/abs/10.1002/csr.1783 https://onlinelibrary.wiley.com/doi/10.1002/csr.1783},
   year = {2019},
}
@web_page{Bruner2021,
   author = {Raisa Bruner},
   journal = {Time},
   month = {11},
   title = {Are Environmentally-Friendly NFTs Possible?},
   url = {https://time.com/6120237/nfts-environmental-impact/},
   year = {2021},
}
@web_page{Calma2021,
   author = {Justine Calma},
   journal = {The Verge},
   month = {3},
   title = {The climate controversy swirling around NFTs },
   url = {https://www.theverge.com/2021/3/15/22328203/nft-cryptoart-ethereum-blockchain-climate-change},
   year = {2021},
}
@web_page{Fountain2022,
   author = {Tony M Fountain},
   journal = {RollingStone},
   month = {4},
   title = {How Artists Can Combine NFTs and Music to Grow Their Brands},
   url = {https://www.rollingstone.com/culture-council/articles/artists-can-combine-nfts-and-music-to-grow-their-brands-1333829/},
   year = {2022},
}
@article{Kentikelenis2011,
   author = {Alexander Kentikelenis and Marina Karanikolos and Irene Papanicolas and Sanjay Basu and Martin McKee and David Stuckler},
   doi = {10.1016/S0140-6736(11)61556-0},
   issn = {1474547X},
   issue = {9801},
   journal = {The Lancet},
   month = {10},
   pages = {1457-1458},
   pmid = {21988763},
   publisher = {Elsevier B.V.},
   title = {Health effects of financial crisis: Omens of a Greek tragedy},
   volume = {378},
   url = {http://www.thelancet.com/article/S0140673611615560/fulltext http://www.thelancet.com/article/S0140673611615560/abstract https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(11)61556-0/abstract},
   year = {2011},
}
@article{De_Vogil2014,
   abstract = {In 2009, Europe was hit by one of the worst debt crises in history. Although the Eurozone crisis is often depicted as an effect of government mismanagement and corruption, it was a consequence of the 2008 U.S. banking crisis which was caused by more than three decades of neoliberal policies, financial deregulation and widening economic inequities. Evidence indicates that the Eurozone crisis disproportionately affected vulnerable populations in society and caused sharp increases of suicides and deaths due to mental and behavioral disorders especially among those who lost their jobs, houses and economic activities because of the crisis. Although little research has, so far, studied the effects of the crisis on health inequities, evidence showed that the 2009 economic downturn increased the number of people living in poverty and widened income inequality especially in European countries severely hit by the debt crisis. Data, however, also suggest favorable health trends and a reduction of traffic deaths fatalities in the general population during the economic recession. Moreover, egalitarian policies protecting the most disadvantaged populations with strong social protections proved to be effective in decoupling the link between job losses and suicides. Unfortunately, policy responses after the crisis in most European countries have mainly consisted in bank bailouts and austerity programs. These reforms have not only exacerbated the debt crisis and widened inequities in wealth but also failed to address the root causes of the crisis. In order to prevent a future financial downturn and promote a more equitable and sustainable society, European governments and international institutions need to adopt new regulations of banking and finance as well as policies of economic redistribution and investment in social protection. These policy changes, however, require the abandonment of the neoliberal ideology to craft a new global political economy where markets and gross domestic product (GDP) are no longer the main national policy goals, but just means to human and health improvements.},
   author = {Roberto De Vogli},
   doi = {10.1186/S12939-014-0058-6/FIGURES/4},
   issn = {14759276},
   issue = {1},
   journal = {International Journal for Equity in Health},
   keywords = {Austerity and Global Health,Europe,Financial crisis,Great recession,Health,Inequality,Neoliberalism},
   month = {7},
   pages = {1-7},
   pmid = {25059702},
   publisher = {BioMed Central Ltd.},
   title = {The financial crisis, health and health inequities in Europe: The need for regulations, redistribution and social protection},
   volume = {13},
   url = {https://equityhealthj.biomedcentral.com/articles/10.1186/s12939-014-0058-6},
   year = {2014},
}
@article{Islam2021,
   author = {Nazrul Islam and Yorgos Marinakis and Sterling Olson and Reilly White and Steven Walsh},
   doi = {10.1109/TEM.2020.3045774},
   issn = {15580040},
   journal = {IEEE Transactions on Engineering Management},
   keywords = {Blockchain mining,Industry 4.0,cryptocurrency,ethereum,smart contract,technological entrepreneurship},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Is BlockChain Mining Profitable in the Long Run?},
   year = {2021},
}
@article{Platt2022,
   abstract = {Popular distributed ledger technology (DLT) systems using proof-of-work (PoW) for Sybil attack resistance have extreme energy requirements, drawing stern criticism from academia, businesses, and the media. DLT systems building on alternative consensus mechanisms, foremost proof-of-stake (PoS), aim to address this downside. In this paper, we take a first step towards comparing the energy requirements of such systems to understand whether they achieve this goal equally well. While multiple studies have been undertaken that analyze the energy demands of individual Blockchains, little comparative work has been done. We approach this research question by formalizing a basic consumption model for PoS blockchains. Applying this model to six archetypal blockchains generates three main findings: First, we confirm the concerns around the energy footprint of PoW by showing that Bitcoin's energy consumption exceeds the energy consumption of all PoS-based systems analyzed by at least three orders of magnitude. Second, we illustrate that there are significant differences in energy consumption among the PoSbased systems analyzed, with permissionless systems having an overall larger energy footprint. Third, we point out that the type of hardware that validators use has a considerable impact on whether PoS blockchains' energy consumption is comparable with or considerably larger than that of centralized, non-DLT systems.},
   author = {Moritz Platt and Johannes Sedlmeir and Daniel Platt and Jiahua Xu and Paolo Tasca and Nikhil Vadgama and Juan Ignacio Ibanez},
   doi = {10.1109/QRS-C55045.2021.00168},
   month = {4},
   pages = {1135-1144},
   publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
   title = {The Energy Footprint of Blockchain Consensus Mechanisms Beyond Proof-of-Work},
   year = {2022},
}
@web_page{Ethereum2022,
   author = {EthereumFoundation},
   journal = {Ethereum Foundation},
   month = {8},
   title = {Mainnet Merge Announcement},
   url = {https://blog.ethereum.org/2022/08/24/mainnet-merge-announcement/},
   year = {2022},
}
@book{Neusser2011,
   author = {Klaus Neusser},
   doi = {10.1007/978-3-8348-8653-8},
   edition = {3},
   journal = {Zeitreihenanalyse in den Wirtschaftswissenschaften},
   pages = {1-304},
   publisher = {Vieweg+Teubner Verlag Wiesbaden},
   title = {Zeitreihenanalyse in den Wirtschaftswissenschaften},
   year = {2011},
}
@article{Long2016,
   abstract = {This paper examines the explosive behavior in the gold market. Using the generalized sup ADF (GSADF) test introduced by Phillips et al. (Testing for multiple bubbles. Cowles Foundation Discussion Paper No. 1843, 2012), we quantitatively examine the existence of explosive periods in the gold market during the period between 1968 and 2013. The date-stamping strategy associated with the test provides a real-time estimation for the origination and termination dates of each explosive period in the gold market, and several explosive periods, including both the famous 1980 explosion and the most recent 2011 explosion, are identified. Our results also demonstrate that, when multiple explosive periods exist within a specific time interval, the GSADF test is more accurate and effective in detecting them than the approach introduced by Phillips et al. (Int Econ Rev 52(1):201–226, 2011), which is relatively conservative. This paper provides further evidence that gold is the safe haven for assets under huge risk and the gold price reacts to political and economic uncertainties relatively faster than other selected commodities do.},
   author = {Wei Long and Dingding Li and Qi Li},
   doi = {10.1007/S00181-015-1030-Z/FIGURES/4},
   issn = {03777332},
   issue = {3},
   journal = {Empirical Economics},
   keywords = {Explosive behavior,Gold price,Multiple bubbles},
   month = {11},
   pages = {1151-1164},
   publisher = {Springer Verlag},
   title = {Testing explosive behavior in the gold market},
   volume = {51},
   url = {https://link.springer.com/article/10.1007/s00181-015-1030-z},
   year = {2016},
}
@article{Liaqat2019,
   abstract = {This paper aims at to investigate the existence of multiple bubbles and specific corresponding events in Pakistan Stock Exchange across different industrial sectors using Generalized Sup Augmented Dickey Fuller (GSADF) test of right-tailed ADF as proposed by Philips et al. (Int Econ Rev 56:1043–1078, 2015a, Int Econ Rev 56:1079–1134, 2015b) by using monthly data for the period of 2007–2016. Findings of study confirm the existence of multiple bubbles in KSE-100 Index along with different industrial sectors. Empirical results depict that Investments, Chemicals and Textile Spinning were the only few sectors where no stock price bubbles were identified. The present study is expected to be pioneer in its nature to apply GSADF for the identification of multiple stock bubbles in emerging stock market of Pakistan which can be further used for comparison of stock bubbles in other regional markets such as BRICS or SAARC regions in order to find out the similarities and dissimilarities in the events causing stock market bubbles.},
   author = {Ayesha Liaqat and Mian Sajid Nazir and Iftikhar Ahmad},
   doi = {10.1007/S10644-018-9230-0/FIGURES/26},
   issn = {15740277},
   issue = {3},
   journal = {Economic Change and Restructuring},
   keywords = {Emerging market,GSADF,KSE-100 index,Multiple bubbles,Pakistan},
   month = {8},
   pages = {301-326},
   publisher = {Springer New York LLC},
   title = {Identification of multiple stock bubbles in an emerging market: application of GSADF approach},
   volume = {52},
   url = {https://link.springer.com/article/10.1007/s10644-018-9230-0},
   year = {2019},
}
@article{Li2020,
   abstract = {Globally, natural gas prices vary from one region to another, which is a key factor worth considering in formulating energy-related policies or in entering the energy market for a well-considering portfolio to minimize the market risk. This study aims to detect the beginning and the culmination of possible speculative bubbles and analyzed the causes in natural gas prices of three key regional markets, namely, the European Union (EU), Asia, and the United States (US). The monthly data from January 1996 to June 2017 are analyzed by a new bubble detection method called the generalized sup ADF (GSADF) test. There are four significant findings. Firstly, two episodes of bubbles have occurred in the EU, six in Asia, and five in the US during the study period. Secondly, in 2008, the bubbles have struck all the three markets simultaneously, as the prices fluctuated rapidly and drastically. Thirdly, an apparent heterogeneity emerges in terms of the occurrence and duration of bubbles in the three markets, as mentioned above. The bubbles in the EU tend to last longer. Fourthly, the qualitative analysis of the occurrence of natural gas pricing bubbles summarized the cause of the bubbles in different markets. The global economic events can create a simultaneous influence. Geopolitical factors are attributed to the long-duration bubbles in the EU market. Economic euphoria and oil price fluctuation are the main contributing factors to the bubbles in the Asian market. Price volatility and speculation activities are the main factors leading to the price bubble in the US natural gas market. This paper contributes empirically to detect and depict the bubble periods for three natural gas market prices and investigates the cross-market different features and causes for bubbles. This research implies the financialization should be considered as the promotion of a hub-based pricing mechanism, the segmentation among different natural gas market in geography and pricing mechanism should be eliminated. This paper suggests policymakers and investors defend the possible bubbles by establishing an efficient market, diversification of natural gas supply, and unifying the global pricing mechanism.},
   author = {Yan Li and Julien Chevallier and Yigang Wei and Jing Li},
   doi = {10.1016/J.ENECO.2020.104740},
   issn = {0140-9883},
   journal = {Energy Economics},
   keywords = {GSADF test,Multiple bubbles,Natural gas price,Regional markets},
   month = {3},
   pages = {104740},
   publisher = {North-Holland},
   title = {Identifying price bubbles in the US, European and Asian natural gas market: Evidence from a GSADF test approach},
   volume = {87},
   year = {2020},
}
@article{Borri2022,
   abstract = {We construct a comprehensive dataset on a near universe of non-fungible token (NFT) transactions, create indices for the NFT market and its components, and analyze their properties. The NFT market return is significantly exposed to the cryptocurrency market, but the majority of the return variations remain unexplained. NFT market returns have low exposures to other cryptocurrency factors and factors from traditional asset markets. In the time-series, volatility and the NFT valuation ratio significantly predict NFT market returns. In the cross-section, NFT returns exhibit size and return reversal effects.},
   author = {Nicola Borri and Yukun Liu and Aleh Tsyvinski},
   doi = {10.2139/SSRN.4052045},
   journal = {SSRN Electronic Journal},
   keywords = {Aleh Tsyvinski,Asset Pricing,NFT,Nicola Borri,Non-Fungible Token,SSRN,The Economics of Non-Fungible Tokens,Yukun Liu},
   month = {3},
   publisher = {Elsevier BV},
   title = {The Economics of Non-Fungible Tokens},
   url = {https://papers.ssrn.com/abstract=4052045},
   year = {2022},
}
@article{Dowling2022,
   abstract = {In early 2021, non-fungible tokens (NFT) became the first application of blockchain technology to achieve clear public prominence. NFTs are tradeable rights to digital assets (images, music, videos, virtual creations) where ownership is recorded in smart contracts on a blockchain. Given the NFT market emerged out of cryptocurrencies, we explore if NFT pricing is related to cryptocurrency pricing. A spillover index shows only limited volatility transmission effects between cryptocurrencies and NFTs. But wavelet coherence analysis indicates co-movement between the two sets of markets. This suggests that cryptocurrency pricing behaviours might be of some benefit in understanding NFT pricing patterns. However, the low volatility transmissions also indicate that NFTs can potentially be considered as a low-correlation asset class distinct from cryptocurrencies.},
   author = {Michael Dowling},
   doi = {10.1016/J.FRL.2021.102097},
   issn = {1544-6123},
   journal = {Finance Research Letters},
   keywords = {Co-movement,Cryptocurrency,NFT,Non-fungible tokens,Spillover},
   month = {1},
   pages = {102097},
   publisher = {Elsevier},
   title = {Is non-fungible token pricing driven by cryptocurrencies?},
   volume = {44},
   year = {2022},
}
@article{Ito2022,
   abstract = {Our study empirically predicts the bubble of non-fungible tokens (NFTs):
transferable and unique digital assets on public blockchains. This topic is
important because, despite their strong market growth in 2021, NFTs on a
project basis have not been investigated in terms of bubble prediction.
Specifically, we applied the logarithmic periodic power law (LPPL) model to
time-series price data associated with four major NFT projects. The results
indicate that, as of December 20, 2021, (i) NFTs, in general, are in a small
bubble (a price decline is predicted), (ii) the Decentraland project is in a
medium bubble (a price decline is predicted), and (iii) the Ethereum Name
Service and ArtBlocks projects are in a small negative bubble (a price increase
is predicted). A future work will involve a prediction refinement considering
the heterogeneity of NFTs, comparison with other methods, and the use of more
enriched data.},
   author = {Kensuke Ito and Kyohei Shibano and Gento Mogi},
   doi = {10.48550/arxiv.2203.12587},
   month = {3},
   title = {Bubble Prediction of Non-Fungible Tokens (NFTs): An Empirical Investigation},
   url = {https://arxiv.org/abs/2203.12587v2},
   year = {2022},
}
@web_page{Goldstein2022,
   author = {Caroline Goldstein},
   journal = {artnet news},
   month = {1},
   title = {Which Celebrities Have NFTs as Profile Pics? Here Are 21 of the Most Unexpected, From Ozzy Osbourne to Shonda Rhimes},
   url = {https://news.artnet.com/market/nft-celebrity-profile-pics-2064502},
   year = {2022},
}
@article{Vasilopoulos2022,
   abstract = {This paper introduces the R package exuber for testing and date-stamping periods of mildly explosive dynamics (exuberance) in time series. The package computes test statistics for the supremum augmented Dickey-Fuller test (SADF) of Phillips, Wu, and Yu (2011), the generalized SADF (GSADF) of Phillips, Shi, and Yu (2015a,b), and the panel GSADF proposed by Pavlidis, Yusupova, Paya, Peel, Martínez-García, Mack, and Grossman (2016); generates finite-sample critical values based on Monte Carlo and bootstrap methods; and implements the corresponding date-stamping procedures. The recursive least-squares algorithm that we introduce in our implementation of these techniques utilizes the matrix inversion lemma and in that way achieves significant speed improvements. We illustrate the speed gains in a simulation experiment, and provide illustrations of the package using artificial series and a panel on international house prices.},
   author = {Kostas Vasilopoulos and Efthymios Pavlidis and Enrique Martínez-García},
   doi = {10.18637/JSS.V103.I10},
   issn = {1548-7660},
   issue = {10},
   journal = {Journal of Statistical Software},
   keywords = {R,Right,tailed unit root tests},
   month = {8},
   pages = {1-26},
   title = {exuber: Recursive Right-Tailed Unit Root Testing with R},
   volume = {103},
   url = {http://138.232.16.156/index.php/jss/article/view/v103i10},
   year = {2022},
}
@web_page{Draht2021,
   author = {Moritz Draht},
   journal = {BTC Echo},
   month = {11},
   title = {Krypto-Kunst: Die KÖNIG GALERIE wühlt den NFT-Betrieb auf},
   url = {https://www.btc-echo.de/news/die-koenig-galerie-wuehlt-den-nft-betrieb-auf-129018/},
   year = {2021},
}
@web_page{Ruchairawat2020,
   author = {Nicha Ruchairawat},
   journal = {Towards Data Science},
   month = {11},
   title = {6 Tips for Interpretable Topic Models},
   url = {https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2},
   year = {2020},
}
@article{Martin2015,
   author = {Fiona Martin and Mark Johnson},
   journal = {Proceedings of the Australasian Language Technology Association Workshop},
   pages = {111-115},
   title = {More Efficient Topic Modelling Through a Noun Only Approach},
   url = {http://www.nltk.org/howto/wordnet.html},
   year = {2015},
}
@article{Fang2012,
   abstract = {This paper presents a novel opinion mining research problem , which is called Contrastive Opinion Modeling (COM). Given any query topic and a set of text collections from multiple perspectives, the task of COM is to present the opinions of the individual perspectives on the topic, and furthermore to quantify their difference. This general problem subsumes many interesting applications, including opinion summarization and forecasting, government intelligence and cross-cultural studies. We propose a novel unsupervised topic model for contrastive opinion modeling. It simulates the generative process of how opinion words occur in the documents of different collections. The ad hoc opinion search process can be efficiently accomplished based on the learned parameters in the model. The difference of perspectives can be quantified in a principled way by the Jensen-Shannon divergence among the individual topic-opinion distributions. An extensive set of experiments have been conducted to evaluate the proposed model on two datasets in the political domain: 1) statement records of U.S. senators; 2) world news reports from three representative media in U.S., China and India, respectively. The experimental results with both qualitative and quantitative analysis have shown the effectiveness of the proposed model.},
   author = {Yi Fang and Luo Si and Naveen Somasundaram and Zhengtao Yu},
   city = {New York, New York, USA},
   doi = {10.1145/2124295},
   isbn = {9781450307475},
   journal = {Proceedings of the fifth ACM international conference on Web search and data mining - WSDM '12},
   keywords = {G3 [Probability and Statistics]: Probabilistic algorithms,H33 [Information Storage and Retrieval]: Information Search and Retrieval-Retrieval models,I27 [Artificial Intelligence]: Natural Language Processing-Text analysis General Terms Algorithms, Experimentation Keywords contrastive opinions, opinion mining, topic modeling, opin-ion retrieval},
   publisher = {ACM Press},
   title = {Mining Contrastive Opinions on Political Texts using Cross-Perspective Topic Model},
   url = {http://en.wikipedia.org/wiki/Public},
   year = {2012},
}
@web_page{Rogers2016,
   author = {Simon Rogers},
   journal = {Google News Lab},
   month = {7},
   title = {What is Google Trends data — and what does it mean? | by Simon Rogers | Google News Lab | Medium},
   url = {https://medium.com/google-news-lab/what-is-google-trends-data-and-what-does-it-mean-b48f07342ee8},
   year = {2016},
}
@article{Chen2020,
   abstract = {Blockchain technology can reduce transaction costs, generate distributed trust, and empower decentralized platforms, potentially becoming a new foundation for decentralized business models. In the financial industry, blockchain technology allows for the rise of decentralized financial services, which tend to be more decentralized, innovative, interoperable, borderless, and transparent. Empowered by blockchain technology, decentralized financial services have the potential to broaden financial inclusion, facilitate open access, encourage permissionless innovation, and create new opportunities for entrepreneurs and innovators. In this article, we assess the benefits of decentralized finance, identify existing business models, and evaluate potential challenges and limits. As a new area of financial technology, decentralized finance may reshape the structure of modern finance and create a new landscape for entrepreneurship and innovation, showcasing the promises and challenges of decentralized business models.},
   author = {Yan Chen and Cristiano Bellavitis},
   doi = {10.1016/J.JBVI.2019.E00151},
   issn = {2352-6734},
   journal = {Journal of Business Venturing Insights},
   keywords = {Blockchain,Decentralization,Decentralized finance,Decentralized platform,FinTech},
   month = {6},
   pages = {e00151},
   publisher = {Elsevier},
   title = {Blockchain disruption and decentralized finance: The rise of decentralized business models},
   volume = {13},
   year = {2020},
}
@article{Nakamoto2008,
   abstract = {A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending. We propose a solution to the double-spending problem using a peer-to-peer network. The network timestamps transactions by hashing them into an ongoing chain of hash-based proof-of-work, forming a record that cannot be changed without redoing the proof-of-work. The longest chain not only serves as proof of the sequence of events witnessed, but proof that it came from the largest pool of CPU power. As long as a majority of CPU power is controlled by nodes that are not cooperating to attack the network, they'll generate the longest chain and outpace attackers. The network itself requires minimal structure. Messages are broadcast on a best effort basis, and nodes can leave and rejoin the network at will, accepting the longest proof-of-work chain as proof of what happened while they were gone.},
   author = {Satoshi Nakamoto},
   title = {Bitcoin: A Peer-to-Peer Electronic Cash System},
   url = {www.bitcoin.org},
   year = {2008},
}
@article{Buterin2014,
   author = {Vitalik Buterin},
   title = {Ethereum: A Next-Generation Smart Contract and Decentralized Application Platform.},
   year = {2014},
}
@web_page{Genc2021,
   author = {Ekin Genç},
   journal = {Decrypt},
   month = {12},
   title = {15 Most Innovative NFT Artists of 2021},
   url = {https://decrypt.co/88533/15-most-innovative-nft-artists-of-2021},
   year = {2021},
}
@web_page{Boom2022,
   author = {Daniel Van Boom},
   journal = {CNET},
   month = {8},
   title = {Bored Ape Yacht Club NFTs Explained},
   url = {https://www.cnet.com/culture/internet/bored-ape-yacht-club-nfts-explained/},
   year = {2022},
}
@web_page{Ubot2022,
   author = {Alex Ubot},
   journal = {UX Collective},
   month = {4},
   title = {DALL-E: the future of NFTs artwork is powered by AI},
   url = {https://uxdesign.cc/dall-e-the-future-of-nfts-artwork-is-powered-by-ai-d1570e14951c},
   year = {2022},
}
@article{Laidler1996,
   abstract = {This Glossary is a compilation of terminology recommendations in the field of chemical kinetics. Every effort has been made to include what appear to be the most commonly accepted definitions. Is is hoped that the Glossary will be a helpful guide to those who are writing books and articles in the field. The reader is warned, however, that alternative definitions of some of the terms, such as Adiabatic and Rate-Controlling Step, are frequently to be found in the scientific literature. Expressions shown in italics are to be found as separate items in this glossary. © 1996, Walter de Gruyter GmbH, Berlin/Boston. All rights reserved.},
   author = {Keith J. Laidler},
   issn = {13653075},
   issue = {1},
   journal = {Pure and Applied Chemistry},
   month = {1},
   pages = {149-192},
   publisher = {De Gruyter},
   title = {A glossary of terms used in chemical kinetics, including reaction dynamics (IUPAC recommendations 1996)},
   volume = {68},
   url = {https://www.degruyter.com/document/doi/10.1351/pac199668010149/html?lang=en},
   year = {1996},
}
@article{Binkley2014,
   abstract = {Latent Dirichlet Allocation (LDA) has seen increasing use in the understanding of source code and its related artifacts in part because of its impressive modeling power. However, this expressive power comes at a cost: The technique includes several tuning parameters whose impact on the resulting LDA model must be carefully considered. An obvious example is the burn-in period; too short a burn-in period leaves excessive echoes of the initial uniform distribution. The aim of this work is to provide insights into the tuning parameter's impact. Doing so improves the comprehension of both, 1) researchers who look to exploit the power of LDA in their research and 2) those who interpret the output of LDA-using tools. It is important to recognize that the goal of this work is not to establish values for the tuning parameters because there is no universal best setting. Rather, appropriate settings depend on the problem being solved, the input corpus (in this case, typically words from the source code and its supporting artifacts), and the needs of the engineer performing the analysis. This work's primary goal is to aid software engineers in their understanding of the LDA tuning parameters by demonstrating numerically and graphically the relationship between the tuning parameters and the LDA output. A secondary goal is to enable more informed setting of the parameters. Results obtained using both production source code and a synthetic corpus underscore the need for a solid understanding of how to configure LDA's tuning parameters.},
   author = {David Binkley and Daniel Heinz and Dawn Lawrie and Justin Overfelt},
   doi = {10.1145/2597008.2597150},
   isbn = {9781450328791},
   journal = {22nd International Conference on Program Comprehension, ICPC 2014 - Proceedings},
   keywords = {Hyper-parameters,Latent Dirichlet Allocation,Source code topic models},
   month = {6},
   pages = {26-36},
   publisher = {Association for Computing Machinery},
   title = {Understanding LDA in source code analysis},
   year = {2014},
}
